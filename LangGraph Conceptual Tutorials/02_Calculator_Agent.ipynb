{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91567e01-fc0b-4104-aca4-45dff1ca53f6",
   "metadata": {},
   "source": [
    "# LANGGRAPH AGENT WITH TOOLS - Building an AI Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5470b3cd-2555-4bb1-96bd-06d386d3d994",
   "metadata": {},
   "source": [
    "    WHAT THIS CODE DOES:\n",
    "    \n",
    "    Creates an AI agent that can use calculator tools to solve math problems.\n",
    "    \n",
    "    THE BIG IDEA:\n",
    "    \n",
    "    Instead of the LLM doing math itself (which it's bad at), we give it TOOLS\n",
    "    to perform calculations accurately. The agent decides WHEN to use tools.\n",
    "    \n",
    "    EXECUTION FLOW:\n",
    "    \n",
    "    ┌─────────────────────────────────────────────────────────────────────────┐\n",
    "    │  User: \"Add 3 and 4\"                                                    │\n",
    "    └──────────────────────────┬──────────────────────────────────────────────┘\n",
    "                               │\n",
    "                               ▼\n",
    "                        ┌──────────────┐\n",
    "                        │  llm_call    │  \"I should use the add tool\"\n",
    "                        │   (AI)       │  Returns: tool_call(add, 3, 4)\n",
    "                        └──────┬───────┘\n",
    "                               │\n",
    "                               ▼\n",
    "                        ┌──────────────┐\n",
    "                        │  tool_node   │  Executes: add(3, 4) = 7\n",
    "                        │  (execute)   │  Returns: ToolMessage(\"7\")\n",
    "                        └──────┬───────┘\n",
    "                               │\n",
    "                               ▼\n",
    "                        ┌──────────────┐\n",
    "                        │  llm_call    │  \"The answer is 7\"\n",
    "                        │   (AI)       │  Returns: final message\n",
    "                        └──────┬───────┘\n",
    "                               │\n",
    "                               ▼\n",
    "                            ┌─────┐\n",
    "                            │ END │\n",
    "                            └─────┘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbe881-47af-42b8-af84-8c06d875a268",
   "metadata": {},
   "source": [
    "## STEP 1: Define Tools and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d0f239-a69b-4200-9245-fb897eac1768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\miniconda3\\envs\\Ollama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\n",
    "    model=\"qwen3:8b\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature=0  # 0 = deterministic, no randomness\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe47707e-653a-4497-856f-ffb8d7e3e2f8",
   "metadata": {},
   "source": [
    "### Define Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654eb58-227a-4fea-95b5-6c0e6ffd5bf1",
   "metadata": {},
   "source": [
    "The @tool decorator converts regular Python functions into \"tools\" that:\n",
    "1. Have structured schemas (so the LLM knows how to use them)\n",
    "2. Can be called by the AI agent\n",
    "3. Include docstrings that explain what they do\n",
    "\n",
    "Think of tools as \"superpowers\" you give to the AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b80e00-2880-4a01-96bf-f32c15d16118",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply `a` and `b`.\n",
    "    \n",
    "    The docstring is CRITICAL - the LLM reads this to understand\n",
    "    what the tool does and when to use it!\n",
    "    \n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds `a` and `b`.\n",
    "    \n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide `a` and `b`.\n",
    "    \n",
    "    Args:\n",
    "        a: First int\n",
    "        b: Second int\n",
    "    \"\"\"\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f4c783-299f-4ef2-b70b-01b48290c819",
   "metadata": {},
   "source": [
    "### Augment the LLM with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee18bc-3ae1-4089-be5e-196afe48f407",
   "metadata": {},
   "source": [
    "After binding, when you call the model, it can return TWO types of responses:\n",
    "1. Regular text response: \"The answer is 7\"\n",
    "2. Tool call request: \"I need to call add(3, 4)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4b38dff-f273-438a-b036-8d10b0aa1a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all available tools\n",
    "tools = [add, multiply, divide]\n",
    "\n",
    "# Create a lookup dictionary: tool_name → tool_function\n",
    "# This lets us quickly find tools by name when the LLM requests them\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "# Example: {\"add\": <add_tool>, \"multiply\": <multiply_tool>, \"divide\": <divide_tool>}\n",
    "\n",
    "# Bind tools to the model\n",
    "# This tells the model: \"Hey, you have these tools available to use!\"\n",
    "model_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92c880-4d2c-46c7-a692-578a93f98a98",
   "metadata": {},
   "source": [
    "## STEP 2: Define State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eb8d4b-64a9-41c8-8563-a31feb589f04",
   "metadata": {},
   "source": [
    "    Defines the STATE that flows through the agent graph.\n",
    "    \n",
    "    State is like a shared notebook that every node can read and write to.\n",
    "    \n",
    "    Attributes:\n",
    "        messages: List of conversation messages (user, AI, tool results)\n",
    "                  The Annotated[..., operator.add] means: when updating,\n",
    "                  APPEND new messages instead of replacing them\n",
    "        \n",
    "        llm_calls: Counter to track how many times we've called the LLM\n",
    "    \n",
    "    Visual:\n",
    "        State at Step 1:\n",
    "        {\n",
    "            \"messages\": [HumanMessage(\"Add 3 and 4\")],\n",
    "            \"llm_calls\": 0\n",
    "        }\n",
    "        \n",
    "        State at Step 2 (after LLM call):\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\"Add 3 and 4\"),\n",
    "                AIMessage(tool_calls=[{name: \"add\", args: {a:3, b:4}}])\n",
    "            ],\n",
    "            \"llm_calls\": 1\n",
    "        }\n",
    "        \n",
    "        State at Step 3 (after tool execution):\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\"Add 3 and 4\"),\n",
    "                AIMessage(tool_calls=[...]),\n",
    "                ToolMessage(content=\"7\")  ← Result from tool\n",
    "            ],\n",
    "            \"llm_calls\": 1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94ab96dd-feec-4695-b6e9-667bbe5d2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AnyMessage\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator\n",
    "\n",
    "class MessagesState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "    llm_calls: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c98ef6-d934-4726-9eaf-d41b8b52bbff",
   "metadata": {},
   "source": [
    "## STEP 3: Define Model Node (The \"Brain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324d918-c888-4ece-8d28-8d9017adbbbc",
   "metadata": {},
   "source": [
    "    NODE: Calls the LLM to decide what to do next.\n",
    "    \n",
    "    The LLM looks at the conversation history and decides:\n",
    "    - Option A: Call a tool (e.g., \"I need to use add(3, 4)\")\n",
    "    - Option B: Respond directly (e.g., \"The answer is 7\")\n",
    "    \n",
    "    Process Flow:\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Input State                                            │\n",
    "    │  messages: [HumanMessage(\"Add 3 and 4\")]                │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Construct Prompt                                       │\n",
    "    │  SystemMessage(\"You are a helpful assistant...\")        │\n",
    "    │  + all existing messages                                │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Call model_with_tools.invoke()                         │\n",
    "    │  LLM thinks: \"I should use the add tool\"                │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Output State                                           │\n",
    "    │  messages: [AIMessage(tool_calls=[add(3,4)])]           │\n",
    "    │  llm_calls: 1                                           │\n",
    "    └─────────────────────────────────────────────────────────┘\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with message history\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - New AI message (either tool call or text response)\n",
    "        - Updated llm_calls counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e6e33d-858d-4bcc-b714-88068b1cfaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import SystemMessage\n",
    "\n",
    "def llm_call(state: dict):\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            model_with_tools.invoke(\n",
    "                [\n",
    "                    # System message defines the AI's role/behavior\n",
    "                    SystemMessage(\n",
    "                        content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\"\n",
    "                    )\n",
    "                ]\n",
    "                + state[\"messages\"]  # Add all conversation history\n",
    "            )\n",
    "        ],\n",
    "        \"llm_calls\": state.get('llm_calls', 0) + 1  # Increment counter\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d4bde-fdfd-4368-b026-ab718462d75c",
   "metadata": {},
   "source": [
    "## STEP 4: Define Tool Node (The \"Hands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101915e-68bd-4a4e-84be-275452a1c5d0",
   "metadata": {},
   "source": [
    "    NODE: Executes the tools that the LLM requested.\n",
    "    \n",
    "    This node:\n",
    "    1. Looks at the last AI message\n",
    "    2. Extracts tool call requests\n",
    "    3. Executes each tool\n",
    "    4. Returns results as ToolMessages\n",
    "    \n",
    "    Process Flow:\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Input State                                            │\n",
    "    │  Last message: AIMessage(                               │\n",
    "    │      tool_calls=[{name:\"add\", args:{a:3,b:4}, id:\"1\"}]  │\n",
    "    │  )                                                      │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Extract Tool Calls                                     │\n",
    "    │  tool_call = {name: \"add\", args: {a:3, b:4}, id: \"1\"}   │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Look Up Tool                                           │\n",
    "    │  tool = tools_by_name[\"add\"]  → <add function>          │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Execute Tool                                           │\n",
    "    │  result = add.invoke({a: 3, b: 4})  → 7                 │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Create ToolMessage                                     │\n",
    "    │  ToolMessage(content=\"7\", tool_call_id=\"1\")             │\n",
    "    └──────────────────────┬──────────────────────────────────┘\n",
    "                           │\n",
    "                           ▼\n",
    "    ┌─────────────────────────────────────────────────────────┐\n",
    "    │  Output State                                           │\n",
    "    │  messages: [ToolMessage(\"7\")]                           │\n",
    "    └─────────────────────────────────────────────────────────┘\n",
    "    \n",
    "    Args:\n",
    "        state: Current state (must contain AI message with tool_calls)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with ToolMessage results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55fc1d4e-a992-411f-9152-1f9fd298003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import ToolMessage\n",
    "\n",
    "def tool_node(state: dict):\n",
    "    result = []\n",
    "    \n",
    "    # Get all tool calls from the last AI message\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Look up the tool function by name\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        \n",
    "        # Execute the tool with the provided arguments\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        \n",
    "        # Create a ToolMessage with the result\n",
    "        # The tool_call_id links this result back to the request\n",
    "        result.append(\n",
    "            ToolMessage(\n",
    "                content=str(observation),  # The actual result (e.g., \"7\")\n",
    "                tool_call_id=tool_call[\"id\"]  # Links to the original request\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54afd0f-9d62-4e06-87b6-bb926abb628d",
   "metadata": {},
   "source": [
    "## STEP 5: Define Logic to Determine Whether to End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ab797-fa48-414d-b8b0-e1e3b048af8e",
   "metadata": {},
   "source": [
    "    CONDITIONAL EDGE: Decides where to route next based on state.\n",
    "    \n",
    "    This is like a traffic controller that looks at the last message and decides:\n",
    "    - If AI wants to use a tool → go to \"tool_node\"\n",
    "    - If AI has the final answer → go to END\n",
    "    \n",
    "    Decision Tree:\n",
    "                    ┌──────────────────┐\n",
    "                    │  should_continue │\n",
    "                    └────────┬─────────┘\n",
    "                             │\n",
    "                ┌────────────┴────────────┐\n",
    "                │                         │\n",
    "                ▼                         ▼\n",
    "    ┌─────────────────────┐   ┌─────────────────────┐\n",
    "    │ Has tool_calls?     │   │ No tool_calls?      │\n",
    "    │ YES                 │   │ NO                  │\n",
    "    └──────┬──────────────┘   └──────┬──────────────┘\n",
    "           │                         │\n",
    "           ▼                         ▼\n",
    "    ┌─────────────┐          ┌─────────────┐\n",
    "    │ \"tool_node\" │          │     END     │\n",
    "    └─────────────┘          └─────────────┘\n",
    "    \n",
    "    Args:\n",
    "        state: Current state with messages\n",
    "        \n",
    "    Returns:\n",
    "        \"tool_node\" if AI wants to use a tool\n",
    "        END if AI has final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f5c5c17-c71b-4e80-b10f-af323e070f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal[\"tool_node\", END]:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # Check if the LLM made a tool call\n",
    "    # AIMessage has a .tool_calls attribute that's either:\n",
    "    # - Empty list [] if no tools requested\n",
    "    # - List of tool calls if tools requested\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool_node\"  # Execute the tools\n",
    "    \n",
    "    # Otherwise, the AI has provided a final text response\n",
    "    return END  # Stop and return to user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3aab39-11cd-4e13-b5f0-568612d6568a",
   "metadata": {},
   "source": [
    "## STEP 6: Build the Agent Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86f327-9e4d-442c-b8e6-a41303bcd813",
   "metadata": {},
   "source": [
    "    GRAPH STRUCTURE:\n",
    "    \n",
    "             START\n",
    "               │\n",
    "               ▼\n",
    "          ┌─────────┐\n",
    "          │llm_call │ ◄─────────┐\n",
    "          └────┬────┘           │\n",
    "               │                │\n",
    "          [should_continue?]    │\n",
    "               │                │\n",
    "          ┌────┴────┐           │\n",
    "          ▼         ▼           │\n",
    "      tool_node    END          │\n",
    "          │                     │\n",
    "          └─────────────────────┘\n",
    "    \n",
    "    EXECUTION TRACE (for \"Add 3 and 4\"):\n",
    "    1. START → llm_call\n",
    "       - AI: \"I'll use add(3, 4)\"\n",
    "       \n",
    "    2. llm_call → should_continue → tool_node\n",
    "       - Tool: add(3, 4) = 7\n",
    "       \n",
    "    3. tool_node → llm_call\n",
    "       - AI: \"The answer is 7\"\n",
    "       \n",
    "    4. llm_call → should_continue → END\n",
    "       - Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3cd867-2ea6-4059-9175-ede0c8afd58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the graph builder\n",
    "agent_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d305abdb-6925-4f59-bcf0-9669b486b292",
   "metadata": {},
   "source": [
    "### Add Nodes (The Processing Units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df6bd4ae-131d-4246-967f-6c074721bb94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1cc1b4cc5c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_builder.add_node(\"llm_call\", llm_call)\n",
    "agent_builder.add_node(\"tool_node\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd92228-b241-408c-9467-a286a7415936",
   "metadata": {},
   "source": [
    "### Add Edges (The Connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f0c718f-b373-4c77-971a-41d378ea1b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1cc1b4cc5c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always start at llm_call\n",
    "agent_builder.add_edge(START, \"llm_call\")\n",
    "\n",
    "# After llm_call, use should_continue to decide where to go\n",
    "# This is a CONDITIONAL edge - it can go to different places\n",
    "agent_builder.add_conditional_edges(\n",
    "    \"llm_call\",           # From this node\n",
    "    should_continue,      # Use this function to decide\n",
    "    [\"tool_node\", END]    # Possible destinations\n",
    ")\n",
    "\n",
    "# After tool_node, always go back to llm_call\n",
    "# This creates a LOOP that allows multiple tool calls\n",
    "agent_builder.add_edge(\"tool_node\", \"llm_call\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad74c2-4516-4200-a396-de3e757cb065",
   "metadata": {},
   "source": [
    "### Compile the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a977306-914b-4d42-8de1-8bcf16819801",
   "metadata": {},
   "source": [
    "    Compilation turns the blueprint into an executable agent.\n",
    "    Now we can invoke() it with messages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb9584b-e04f-4188-9436-e6799f011d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = agent_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31818bdc-0327-45f9-9adc-ddc13e3cf849",
   "metadata": {},
   "source": [
    "## STEP 7: Visualize and Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7946015-8f8d-451c-9bda-29a23c9615db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD5CAIAAACMBM+DAAAQAElEQVR4nOydB3wU1fbHz8y2JJuQHtI7oUkACaAivUgRKRaK8hBEBEVBQVFEEJSiFH2glMBfkCYPBAERUN4TVIJ0iPSaThJIz6Ztmfmf2UnZTXZDQrLL7M79ymedvfdOyexvzpx7bpOyLAsEgpiQAoEgMojoCaKDiJ4gOojoCaKDiJ4gOojoCaKDiL4eFNzXxR/Lzc5Ql5UwWg2rLWW4VAoAo74SAB33SbHAMsBSLE1TrE6fLwEuLsxQFA24A8UAt8EwNE1z4WL8R1fkMix+UrgzlwhYmttXh58sq6P4bYSluH2BPxH+R1FURdjZ8Lw8MkdKKqUVThKfYEWHXh5yByBQJE7/QFS5uoMb0++llqLIJFLKqYlUpqBRnZoS1CP3H95DSoJS4z45gTPAKQ83ddy95RKxjI6haNxApaKyKYZlaUp/8yv1Teu1zumXAoblnyIukak4uH6bOyAeBg/F8ofC01GVl8pn8eflkTtKdFpWXcaWFeu0WkYqoX1DHYe+6Qcihoj+AfzfnITiQq27tyKqg3OnZzzAxjm2J/tmfKEqT+PhrXh5VjCIEiJ6sxzckHnrnwKfIIcR7wWBfaFTww9LkwtyNO26uz812Oaf5PpCRG+ajfMTtWp2wudhYL/cS9X+9G2yu5fipekBICaI6E2wY3kaOscvvisKKWyan+If6dBntDeIBiL66qAT7+Yhf36aiIzf5gUpEgmM/tDevDhz0EAwYOuiFBc3cSkeGfNxkLqM2RebDuKAiL6KuL3ZqgLNS++JS/E8r84NSbtZnHK9BEQAEX0VF/7M6z/GH8TKY0+5/vLdXRABRPTl7F6RpnSVhrQSb4tl12FeEil9dOd9sHeI6MvJSCrtMcwHxE2zdi7XzhSAvUNEz/HX7ixaRoe2cQQr8uGHH+7duxfqT9++fdPS0sAC9HjRS6dlk6+WgV1DRM+RcKXIJ0AO1uXKlStQf9LT03Nzc8FiuLhJTx3OAruGxOk5Vn9wp8sgr+juTcACJCYmrlmz5uzZs3iro6Oj//Wvf7Vr1y4mJobPdXZ2Pnr0qEql2rJly99//3379m0vL6/u3btPnjzZwYGrYHzwwQcSicTPz2/Tpk1vvPHG2rVr+R2xzLJly6Cx+XXTvZSbRRM+s+emaNK1mOvMyOhYCylerVZPnDixY8eOK1euRO2uW7fu3XffPXjwYFxcXJcuXT755JMhQ4Zgse3bt2/cuPHzzz93c3MrLCxcsmQJFn7nnXcwSyaT3bhxo6ioaPny5W3atGnZsuW0adPQLwoIsEhoNaKt8+2LhWDXENHDncvFtMW8vKSkpJycnFGjRrVo0QK/Ll68+Ny5c1qtFqVsWOyVV17p3bt3WFi5fY2Pjz9+/Dgveoqi7t69u3nzZt7wW5rIx5x+s/d3PxE9qPI1lMVEHxwc7O7u/umnnw4cOLBDhw5t27blHZuyMqPKIj4D6NvMnTsXjTo+Epji4VHV+REfBusonkMCwLCqHHC2386XpCLLDWJiKQosg0KhQJfm6aef3rZt22uvvTZ06NADBw7ULIbOT2xs7LBhw/bs2XPmzJlx48ZVOwhYEZamWNCB/UJED8omcsOhRo1OaGgoeuH79+9HpzwyMnLOnDnXrl0zLIAV3F27do0YMQJF7+vriyno1sMjhGFdPCRgvxDRQ3ALJT8MzxJg6Gbfvn24gf5Jt27dvvjiC6lUevXqVcMyGo2mpKTEx6e8aQzrvn/++Sc8IpKvloKlXntCgYgeFPomqWunVWAB8vPz58+f//XXX6ekpGCldsOGDeiyo2ePHguq/MSJE+jM0DSNbwN8NlJTU/Py8rA8xjQLCgowYlPzgFgSPw8fPnzp0iWwALfiVVKpnauCiJ5D7kBfOZkPFgD1PWvWLIxRouvy/PPPnz9/HmP24eHhmDV+/PjTp09Pnz4dzfzChQvxVfDCCy+g09+pU6cpU6bg1z59+mDcptoBAwMDBw8ejAfBagBYgLTbRS7uMrBrSOMUx8GNGYlXiiZ/GQGiZ/XM292HNG31lDPYL8TScwx41VerYXLvaUDcnPlvHqsD+1Y8kDh9JU08ZPti08bODjVXAB0PdLhrput0OnTKKTNBTwxBYiMrWIALFy5gUMhkVu2XdOTIEXNZF47mBrd0AnuHuDdVrHz35qRFkTIH04LIyMjAiD7UE39/C45Kqenx1wVzl3TpWMHRn+5NWRYJ9g6x9FWEtXL5fkGiub5WfARdUDTuE/XX3vsxfbxABBCfvopnX/dFn+DghgwQH9uXpLh6yZ8YYBFPTGgQ0Rsxfn5o8vXiM79asMO6APl5bboqXzt6plimACE+vQnWzUqIaNuk1whPEAE/fpWmVutGzxTRvJZE9KZZ+9EdVy/FSHuf727zgiStmh03LxTEBBG9WbYtTs3NKm37tNvTQ+2wendoY8btiyr/cKdhb4lu1hMi+tqI/6swbt89vEX+YY59Rvu6uNt838PsVPWRXfcyk0vlDvTgCUG+YXbe48AkRPQP5vSh3PN/5ZYV6yRSSukqc1RKlK5SmYwqK63qdE5LuBUTKu8lJeFWXKgM6+vXDdGvE8Ky/DbLL2LCLdPA8uuRcANZWOCPgG1HFE0z3DoOXJdHhtEfQZ/LD/LSp3D7Mvp1TfTp3HoQfDrD6Jcn4a4AZA4SRs0Wq3SqPE1JkY7RgdJV0nmAd8uOShArRPT14MTB3LRbJYW5Gq0GBQ7oDVdmVYqSR78gDmXwlfvkVh1hyxtDK8Wtv/8Uv61v/KL4ErR+OZLKwvwGv36JYUr53iwXhmNp0C+CAvzDpj84yBUsRUvkCsrZXRbaUtmuhyuIHiJ6AbFo0aLmzZsPHz4cCJaEtMgKCK1WK5WSX8TikFssIIjorQO5xQKCiN46kFssIDQaDRG9FSC3WEAQS28dyC0WEET01oHcYgFBRG8dyC0WEOjTV5vjkmAJiOgFBLH01oHcYgFBRG8dyC0WEET01oHcYgFBRG8dyC0WEKQiax2I6AUEsfTWgdxiAUFEbx3ILRYQRPTWgdxiAVFzATaCJSCiFxDE0lsHcosFBBG9dSC3WEDodDqJxJ5XOBMIRPRCAc08Ubx1IKIXCqRlymoQ0QsF4tBbDXKXhQLLsgEBdj5frEAgohcK6NCnpKQAwfIQ0QsF9G3QwwGC5SGiFwpE9FaDLL8jFNC9YRiGTC1qBYjoBQQx9taBiF5AENFbB+LTCwgieutARC8giOitAxG9gCCitw5E9AKCiN46ENELCCJ660BELyCI6K0DEb2AIKK3DkT0AoKI3joQ0QsIInrrQEQvIIjorQMRvYAgorcOZMXwR8/jjz/Ob1AU93PwdOrUKTY2FggWgHQ4e/R07doVP2maRtHjp0Qi8fDwGDNmDBAsAxH9o2f8+PGenp6GKREREfyTQLAERPSPnrZt21Z6OIiTk9OIESOAYDGI6AXBhAkTvL29+e3g4OA+ffoAwWIQ0QuCZs2ade7cGTcUCsVLL70EBEtCojdmuXRclZ5QUlqsMUykaIplqu4YLQFGZ7wbRUHFLaVpYMGovOHuFGdwqr4WFxefjz8nlyk6xnTELJbRWyTG4MASitXpC+MZuD0NTqoviadjGCwGrM7odJT+MqDyvFT5j+7oJAuLdo5o4wgig4jeBKk3Sg5+n4ECksoodQljlEezwFCV3yiaZQ2+6uEEWVFY/9VceYpTL8tW5bK0Dhia0mdwhwHG8FXMUtx//I4sVGzzR9I/aOWPCsVlVl0Aoy+PpSvOi5n8A6NwoNVqRq6gx88NBTHNoklEXx1Vnm7zwqR23T0ee9oNRMDJg7k3z+VOXBQuntljieirs+b92y9Oj5CL6Z1/53zJyUMZExeHgTggFVkjdq1Ic/ZQiErxSHh7R6mC+v2HLBAHRPRG5GVpvAIcQHy4uMvvJhaDOCAdzozQlOpoUS6MwDJMaYkOxAERvREYsWEYsfz2huh0LCua/p1E9ATRQURvDFWt1UcsYIyfEk39jojeCIqr2lMgSsQTvCaiNwJ/d0aU7RYs30AsDojoqyNSO8+AeFopieiNYClgRal6vU9PLL0ooURr6TnXjgFxQERvDCuit7whnOBF844joieIDiJ6YyiR9kaipSCREksvSjjvRpSqZ3Sg04nFpye9LI1hqXpV5+7cudWzd8zFixdw+9N5M2e8/yY8OoYO77Np83rc2LV7e59+neu3M0t8erEi2tCNqCCiN0Y8zZLGkL43IoaFRolYoqfx6tg3UlOTd+3+wc3N/cknuk55a8bCxZ/Exf0RFBTyyujx/foNqv0IOp1u549bv9/ETWfZqmUbPFqbNu1wOyHh9r6ffzx3/nRGxt3QkPCBA4cOee4FaDDo1IkmTE98+po0hqmXyWTb//N9cHDorwePT3jtrYOH9r373sTevfof/vVEzx59lyz7rFBVWPsRYtet3Lt35/x5S2fPWuDt3XTmR28nJydi+rerlp0+/ffUd2YuXrQCFf/vFV+cOBkHDYaiWW6iB3FARG8E95ZvJP+mWWSL5wY/L5fLe3Tvi19bt45GuUul0p49+mm12uSkhFr2zS/I37Fzy8iRYzvGPNGlS/cZ02fHdHgiO4cbw/rJJ4uWLFn1ePuO7dvFoI1vHtXy1Onj0GC4iUkYUpEVJY34lkczz28olUr8DA2N4L86OjrhZ2FhQS37Jibcxs8WLVrzX/FRmT9vScUlsrt3bz95Ki4lJYlP8PMLAEJ9IKI3pvEqspTxK4Om6/FSVemdHwdF9SHqDMN8OGuqRqN+fcKUdu1iXJxd3p76GjQG+IqjRdPhjLg3xjRSRbaBKJXOwE30V1Qt/cbNa9euXZ486d2uT/dExUPF49FwWG5wMPHpRQk3I54A7F1kZHN0aeL/Ocd/ZVkWDfyvv+7Pz8/Dr95ePnx6YuId/AeNAQlZihcJLYjOxc7Ozn37DMTojaurm6+v/19//X727Mk3J72rUDjgw/CfHZvfeGNqXm7Oym+WYE03IzMdGgwJWYoXhhHKUFEMSqLXvmz5gvemT7p48cL8T5dgzbhpU9+PZ31+5erFIUN7zZr9LgZDn3vuhatXL40d1wihevFA5rI0YvX7tyPaOj85uCmIjP3rUlQ52tcXimI6S+LeGCHageGCqL9bCyJ6I2gJZbXI3eDnepjLmjnz06e79AArIpECJSVTgIgSRsdaLXIXG7vNXJa7mwdYF50WWC1pkRUlGK+0WhONn68/EB4FRPRGiNenFxNE9EZwPr0QWqesD2mcEi2cTy/KGC73oJMZzkQKDeK09KwwOh1ZByJ6Y1gQ62xPxNKLFUpEcwIYQYlpQkMi+uqIc2A4Syy9aMHfnYQs7R4iemOI4kUAEb0RUgUlk4rxnsgdJAolmapblMgVUlW+BsRHiUqrVIplBV0yiMSIZm2V91JKQHwU5mlj+nqCOCCiN6LLEE9XT/nelakgJnYsTQpupgxp7QjigIycMsHmBclaNRPYfbXKZgAAEABJREFUzMUnxIFfQJylKKriRuE2zS9AicFtLo0tLwA1Gra4JK5QZXJlMYpbrpYtj4+yRuWrDsLNR1L1A3GXUHEKLp2qOB3FH4G7LJYx3JfLxyZmBhh9As3qNyrKY5Y09ZbqbmKxt79i6GQ/EA3EpzfBFdXqYPng5BsBty/madXVjQIv2OpUk69heZOx/wrlVW3wczGUq7Xia/lzxZfUH6nGXlXlWaPp2fjz6p9WtvoufAEJI1dQgS2g6xBrd99/tBBLb0RmZmaTJk2OHTvWt29fsDqLFy+OjIx84QVrjPJ+5513/vzzTwcHB2dnZ6lUihv+/v4BAQEff/wx2DvEpy8nOTl54MCBaAIcHR0fieIRVz1gFVD0oaGhWq02Ly8vKysL//yTJ0/u2rWrffv2YO8QSw/Z2dmenp6HDx9u27atj48PiIalS5fu2LGDYarC8zqd7vz582DviN3Sx8bGLliwADfQuj9yxePjV1xcDNZiwoQJQUFBhimBgYEgAsQr+vR0bmIw9OCXL18OwmDJkiXHjzfCvNt1xM3NbcCAATKZjP8qkUjQrVepVGDviFH0hYWFaOTQkcXtkSNHgmBwd3d3cXEBK4L3AYXO6kGffuLEic8+++wvv/wCdo0YfXqMWmB9ET14IADs3r0b33Vo9ffv38+nzJ07F70sfO2AnSIiS49V1f79++NGt27dhKn4+/fvl5WVgXUZPnw4hnEqFY/MmzcPA1mdOnVC6wD2iChEj2ICfVDy0KFDIGBmz5596dIlsDpbtmypltKzZ88TJ07s2bPns88+A7vDzkWPMbg5c+bwYbjXXmucRTssh4eHBzYVgTCgaRrdnujo6D59+ly4cAHsCHv26fFPO3fuHDay4ssaCA9Lfn7+9OnT27RpM3XqVLAL7NPSX716dciQISj6Dh062JDi8flUq9UgMLDSv379enwLDRs27M6dxln45NFib6IvKuLWaTp69OiqVavqtbaZEEBTmpKSAoJkzJgxK1as+PDDD7/77juwcexK9KtXr966dStuTJ48OSDA9haa9PT0dHQUbqd2bL7dsWNHaWnp2LFj+VYOG8VOfHr8JTBE89tvvwm/tmoHXL58Gb18bNiyTofQRsfmLX12dvakSZNKSkqwZdHWFZ+eno7hJhA8rVu3xuDvrVu33n77bes3LDQcmxc9vnDR5GADvkRi8+Oax40bl5eXBzYC+vejR4/u1asXvmDBprBV0e/bt48f7oDue0xMDNgFPj4+CoUCbIcnn3wyLi7ujz/+sK2hJ7YnevRk8JUaHx8/f/58sC82bdoknMapurNgwYLu3bt36dIFG3HBFrCliiz6uwsXLhwxYkRkZKTNhSPrQmpqqu32aEdLhLVbvH50e0DY2JJ0Nm7c2LZt26ioKLtUPIKtP7YbTEPH7JtvvkF71L9/fwzvgICxAUt//vx5rK0uWrQI7Br8ITACuGvXLrBxMISPJr9z585vvvkmCBJBm0y+TX7Lli3Tpk0De4eiKDtQPOLl5fX99987ODigIyrMBmbhWvp169a1aNGia9euIA7wh0hISAgPDwd74fbt2zNmzBg5ciSqH4SEQC39qVOncnNzxaN4RKPRrFq1yj56dPFERET89NNPJ/WAkBCo6DH0/sEHH4CYkMvlS5cuPX36NNgXRUVFUoHNfi5Q0aPBS0tLA/HBewJfffUV2Au3bt3CkA4ICYGKfv/+/UeOHAGxgi86+4hW3b9/H99gVpu2rY4IdAJXDMYLuZOtpcHKDFbiQf/Gs+mq7c2bN5s1awYCQ6CiJwP8vL298XPnzp3t27fv168f2CYC9G1AsO5NYmJiUlISiJ6ZM2fyM7HZKET09eB///vfgQMHgAAwduxY/FyzZg3YIET09SAsLCwkJAQIFQwePPhRTSDeEIhPXw969eoFBAMCAgIOHz6MG9evX2/evDnYAtgii7VwihLcGuwCtfSpqal4y4BQg+Tk5GXLloEtIEzfBgQr+uPHj+/evRsINUAnx9/fX6OxgcVuiejrR1BQUEREBBBMMWrUKGzY37NnD74PQcAI06EHwfr0Tz75JBDMg47yoEGDXnzxxW3btjk5OYEgIZa+fmRkZGCNDQjmkclkaOxLSkqwTQOEh0qPr68vCA+Biv7cuXP8XGWE2vH09ESrL8CpVQVr5kGwose6mq0E5h452KDx0ksvxcfHC2qiKME69CBYn76dHiDUjS5dumi1WgzyZmVlPfXUUyAA0NJHRUWBIBGopccfT+Aj6oUGxnNQZNu3b6/WvvHcc8/Bo4C4N/XmypUrdjAltPVZsWIFOjmVy2LGxMRgSGDt2rVgdYjo642Xl1fr1q2BUH/Q3mNgZ/jw4XxXDoZhDh48CNbl7t27rq6uSqUSBIlARd+qVavx48cD4aFQKBRo7AsKCviv9+7d27t3L1gRIZt5EKzoc3NzMRwBhIcCzXxOTk7l19LSUmzDAiuCohds6AaEPDB81apVQHgoEhIS0Kup/ErTNPob1hxzjKIXci8SgYYsPTw8oqOjgVArt/8p0ZQZ9DyjAPQzd40Y+N7d9LuMVltaVlaQX8DoUw/8J97PuQPouzCwLEtRUD7NF9o9BmocpOJYFf+vdgqgWMBj6A9ldAR9gbwUJwdt2LXTBSaOYHQM7r/yVJoCpsa8Y3zRmkegTE9SppArwto+eK5zYc1wNmHCBHRG0UppNBr+wjAWgW9nvis5oZItC5MLcjU0DVq1mZ9Pr2nKTBZqiNeSWR6QXZFfU5QV29wzwR+ihmSrDoJXSFXfseal1h2pnGYZcPOSj5pZ2+TPwrL0LVu23Lp1a7VJiTGSAwQDYmclePg6DBgfLBfvfBFmUeWwR35M3zAvadxcsyPvhOXTv/LKK0FBQYYpaPVJj0tDYj+606KTxzNj/YjiTeLsQQ2e6O/t5/Td3ERzZYQl+qZNmw4YMMAwxdvbe9SoUUDQ89vme1KFpH1PYc2dJEC6j/DWadm4vTkmcwUXvUGJG67Gwa/CAAQ9GQmlnj4OQKgDLh6KpOvFJrMEJ3psyRs0aBC/VKCnp+eYMWOAUEFZmVbqILhx1sJEIoXSYtODKoUYpx89ejTv2WO7bJs2bYBQgVbD6rRaINQBrVqnU5vOalD0pqQEzhzMSk8sKynWlhXpMMLEMAYBYH28iZKwrK4qdMXnVgaqDOOlXBaUh6h6hCzUBWplMvnaj+5gEMowdEXjARmK37HqXFB+zJrpwD30tERKSeSgVEpCWik79nMHgoh5SNEf3nwv4YpKU8bSEgolJXWQypyknDQZ1qDtQb9RrdGhKtdApDWyFSAv/0YZN52U78ganaL8eTIb06XQV6Kk2jLt/UJNZmrOiYPZTi7SVp1cnnzWE2wKqjw2Tngw+ltlWhD1Fv2hjZl3LqkoCd3E2zmgtY2JhkenZlIvZZ07khv/V377Hu6dB9iO4aeI5OsMjfbW9N2qn+hjP05gGCqoTVMXHxuOEkvkdMjjPrhx72bemf/l3Dxb+MrsYLAFWKbyHUd4AHivGMZ0Vl0rsncTSr9975aLh7JFtyCbVrwhPs3cWvcO1bGSVR/YxkpPbLkbR3gwFA3mJhSsk+gLc3S7V6a27B7q18om/ZnaCYnx9Qnz+naGDcwiiPUjmmi+jrBmffoHiz7xcsmmhYmP9Q2j5XZ7v71ClaHtA1YJXvdY7bfdJcWtjflK/4NF/8uGu82fCAJ7R+kh8wxyWzNT2H4OMfN1hqv/PJxPv352EkZppEoJiICmUW60jP7hSyEucl0OsfKNQW2i/+PHbI1aFxQtop69UV2CstLLMlPUQLB1aK5h1EyOeS7+nesV4gYiQ+nh+PNagS5hy40YIi5OHUH3RldPn/743myM7XuHC7QX64WL/53xSWdVUS40NuExvqVFuoJsAU2RZwBLW93FGTq8z6bN68HyHDl6uGfvmLy8xv9Nq2FW9JdPFzi6iXScgsxBenhbJggPtv5NU/Pmf3jgoFXn/xA+ZkVfVqTzjfIAUeLspbyXUgJ2wfXrV0CU0LTeGTSF6W4Il0+oaAnl6CIDy5CY/M9vR9anpF5xVrq3bP50v54THBy42bDiTuw8/Md3k8ev3rT9o8x7d/yaRnZ7alTHx5/l99p/aOWZ+AMKuVP76Gd8vCzYccAn0j03rQBsH/QW8HPJ0s9Wr/nq571HcTsu7o/vN8UmJSe4urpFRjaf+vbMpk3Lp5CvJeuB/LRnx+Yt679eHjt33geJiXfCwyNffOHl/s8M5nOTkxO//vfiGzevSiTS0NDwV8e+0b5dDJ+1Zu2/fzv8i5OjU+/e/QMDjUa1Hvr1530/70pIuBUWFtmrZ7/nh4+q15ptDMPN+WAyy7SlT77KdSkDy5CVnbJ249saTdmUievHjv4iPfPm6u8m63RcN3GJVFZSUrjnl6UvDZ21ZP6J6Md67djzeW5eBmYdP7Xr+Kkfhw96f+obGzzd/Q8f+T+wGDI5hY3YN86qQGjUsxJ76EAcfr4/4xNe8WfOnpzz6fv9+g3asf3A3E8WZ2amf71iMV+ylqy6IJPJVKrCFSu/fH/6J7//93T3bn2+XDI/M5P74XJzc6a8Pc7Hxzd27bZvV25wd/P47PNZxcXcmKa9+37cu2/n1Hdmrlq1yc8vYNPmdZUH/O//Dn3x5byoZi22bdk34bW3fty17ZtV9VteTiKjJNL6iF6Vz0illorNn4s/JJXIXh31RVPvUF+f8BeHfJyWfv3S1T/4XJ1O07fnhJCgNvhYx7QbhE9rWvoNTD/2947o1r3xMXByaoK2PzI8BiwJvhwzU8pAYOA9oRuwQuV3G1Z369rrhedHoy1v3Tr6zcnvnThx7Jre/6klq45oNJqx/5rYqhX3wz3T71n84W7d4taS2fnjVrlCMWP6bH+/gMDA4PdnzCkpKUatY9bun7bj49G9W+8mLk3wtfB4+46VRztwYE90dPtpUz90d/fA9HFjJ+3ZsyO/IL/u16PjBtzUJ2SpUWtZi0XG0LcJCmylVJYHQz3c/Tw9AhOSLlQWCA4on7rVybEJfpaUFuIdzMpJaeoTVlkm0L8FWBL860uKBLeCH8vgfw8fvblz52aLFlXT4jaPaoWf165drj2r7lQewcWF++HQ9nNHTrjVrFkLqbTckVYqlUGBITduXOXMWVoKejuVu0dFteQ3GIa5dDm+Y0zVLBjt23fERP4pajhmuxZTFguNlZSqUtKuYMDRMLGgMLvq1DWMWWlZEcPoFIqqFcXklp4BA60Ba1cRcZVKVVZWplBUjSvnV2grLi6qJQvqg0mfOyc7KyDAqBuLg6NjcUlxUVGRTqdzdKz6TR0cyn9TtVqN743/+24V/jPcsaA+lh6vhaLrU5GVKbAty1JjMV1cPMNC2j3Ta6JholJZW4OAg0JJ0xKNprQypUxdDJYE7amTi0DnPHw4HBw4TZeWVkWlivSa9vTwqiULGoyTUllaVmqYUlJcHBgQjCZfIvEdQWEAAAZ6SURBVJGUGWSh21N5qfjU9es7qFu33oY7BgeFQp3hwrtMfQaRuHnIstMt1RTv37TZ2fgD4aHtK2cyy7h3x9uztmgMmhB3N7/E5Ivdu5SnXL0eB5aE0bF+IYJrpuCs18P69OhgNI9qefnyP5Up/HZ4RLNasqDBoKf062/70XJjZRe4V3oBBoiwxox/SNOmftyJXiwveeLkscq9IiKiClWFlUEe3D09Pc3Dox4922kpVmTNZJlMDWmh1GnMdFFrMBiFRP9s38Gv1OrSe/eT9v/6zbJvRqdn3qp9r7aP9bl45Qg2xOL2739tSkq9BBZDrdIBw0a0E9z6rCxQUB+fXqFQeHv7nDlz4vyFM1qtdtjQEcfiju7a9QMqD1NWrV6OdcRmkdyCdrVkNZDBg58vKlItW74AgzkYzVy0eI6DwmHggKGY1bNH3z//+h0bYnH7h+3fX7lysXKv11+bEhd3FJvVUCoXL16Y/9lH782YpK3PTBCMltWZKW76WYjqqPxtO1uUrVZ6yqGxwfDLjCnbjvy1+es1Y+/dTwwObP3i0I8fWDHt031cUVHungPLtuz4GL2j5wZM27ZzjoU6l2cm5kkUgpzEvP5/8Mujx2/YuObU6eM/bNuP9vV+1r3/7NyM4T+Mwcd0eOL1CVP4YrVkNZDAgKC5cxZv3rx+5OhnMTTUsuVj//56Pb9IySsvv5aXl7vymyWo6TZt2mHIaMHC2fyfiF9j12zdum3D2tgV6He1bhX9+WfL+XdFwzE7a/H3nycxrDQsRoiL31qa63+m+IY4DJkkuL999Qe3AyIde47wB8KD+CU2pSBPO3FBWM0ss/aszVNuxfmlIErUpZohE8X4tNsT5kcLmg9ZPt7L9dRv2Rk38nyjTPcuxobSZd++bDLLUeFcUma6OdPXO3zKxHXQeMxe0NtcFrbySkzVZUKDoyeM+crcXrdPZbi6KwS6RAv98BXZBvLRx9MuXbxgMmvgwKGTJ00DgUFLwVyLbG1RuXbd3M7+nmtO9E1cvN57c7PJLKyhyuWm5xml6UaOA5q7Bu4yNGVymYl1KaSS2ioqJfklLy8Q6iJhzCMbIzvjvdlqjemAnpOj4Gr8wFVkwVyLbG0SfGKgx7UzhYlnMkJNefZoRD3cH71z2bjXcONYSkAzpQOZ+r0Gnp72M4DuAW/xV+eEFBeU5mfYST/b2km7mI0tB8Mm+wHBrnmw6zpxQUTqJSGOqGhcMq7lFmSrJnwWCoKGBTJcsME8WPRSObz1ZcSlwwkF9mvvUy9m5WUWTP4iHIQORWZEqCPUww0Mr0ICU5ZHplzKSDidDnbHjWOpqmzVpMXCV7x+AleKWPo6U69BJCZ5a1kkNuxeO5qUecviQ3etQ0p8Fr7BmrhKJn0h3JV+DeF+QzLDWd2oZbKn+gUQx88LPXkg9/wfOTmphY4uCp9ITydX2+uKmJ9RdD8hv6xILVPQz70eGNzSdlZxIpP6NQb1lmznge747+ShnMsnChJOp1A0TUu4laMpCTeohzWcHZmqWEKXrVgbpHytXf1q0xVLM1Rus7g/U7GQiH5KapbmFpUut236xR30y1TTfApbvvR1RcNbxRoQXFrlir78eaUYlaE1Gh2j0WLsFtNcPOQ9hvlFthdigLkWyKQ39YAyO2vxQ9rpzv098B9uXDtbdOcfVX4WtkfpWB0YdWA2WG8HRccwVSlgap0cSsLws/NQtN6gsfoGSCh/SdESltGV/yXlry1KPyGGBJte9d9Q7gyrL8aWr15QcV5axijklFQubeLp0DLGJbiljWmd8DCwZj3BhjonLToo8R8QCLaDXQ0OsnukCkomE8Vkug1HLpfIFaZrskT0toRCIS0tstTgHjtDrWEUTqaDk8LsTEgwTUiUMjuTzKhcJ1TZmmZtm5jMIqK3Jbq/5IkxrKPb7wOhVg6sS5c5Sjr0Mz3bAEUivzbHxvlJEpmkQx+foKjGH8xp69z+pyj+SLZCSY+cHmiuDBG9TbLjq7ScjDKGYRmtWRffYGV2Mz12qto4zByhYhX3iq81mwke3BfIcIF48ycqP3Kt/ekefC6JlGs18gl0GjaltoFvRPQ2TEmJfuIGHmNJVGoIjBtDjEoa7mKwXbVZbSX2ii1s/KNYqraSJs9ClbesQI1rMToOmNI2v6+ZC67E1VkCdRgLQURPEB0kZEkQHUT0BNFBRE8QHUT0BNFBRE8QHUT0BNHx/wAAAP//yVIKbgAAAAZJREFUAwBgzJovNY6sgAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph (optional - requires IPython)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(agent.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    print(\"(Skipping visualization - not in Jupyter)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347730c0-85b2-4fbb-9642-f88a2f6cc32e",
   "metadata": {},
   "source": [
    "## Run the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b748abca-38d0-4e4d-a8b0-0f37524b8e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING AGENT: Add 3 and 4, then multiply by 2\n",
      "======================================================================\n",
      "\n",
      "[Agent Execution Trace]\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Message 1:\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add 3 and 4, then multiply by 2.\n",
      "\n",
      "Message 2:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user wants to add 3 and 4 first. Let me check the available functions. There's an add function that takes two integers. So I'll call add with a=3 and b=4. That gives 7. Then they want to multiply the result by 2. The multiply function takes two integers, so I'll use that with a=7 and b=2. Wait, but do I need to store the intermediate result? Since the functions are called sequentially, each step's output is the input for the next. So first call add(3,4), then multiply the result by 2. The tools don't have a way to chain operations, so I need to handle each step separately. Let me make sure I'm using the correct parameters for each function. The add function's parameters are a and b, both integers. Multiply also requires a and b. So first step is add, then multiply with the result and 2. I should return two tool calls in sequence.\n",
      "</think>\n",
      "Tool Calls:\n",
      "  add (2548e91e-0474-43d8-aa0d-9dc7164a6e2d)\n",
      " Call ID: 2548e91e-0474-43d8-aa0d-9dc7164a6e2d\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "  multiply (392ef8ad-b4d4-4307-a2db-ed6210efe8d9)\n",
      " Call ID: 392ef8ad-b4d4-4307-a2db-ed6210efe8d9\n",
      "  Args:\n",
      "    a: 7\n",
      "    b: 2\n",
      "\n",
      "Message 3:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "7\n",
      "\n",
      "Message 4:\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "14\n",
      "\n",
      "Message 5:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, let me see. The user asked to add 3 and 4, then multiply by 2. First, I called the add function with 3 and 4, which gave 7. Then I used the multiply function with 7 and 2, resulting in 14. The user probably wants the final answer, so I should present that clearly. Let me check if there's any more steps, but no, that's it. The answer is 14.\n",
      "</think>\n",
      "\n",
      "The result of adding 3 and 4, then multiplying by 2, is **14**.\n",
      "\n",
      "======================================================================\n",
      "Total LLM calls: 2\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RUNNING AGENT: Add 3 and 4, then multiply by 2\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create initial message\n",
    "messages = [HumanMessage(content=\"Add 3 and 4, then multiply by 2.\")]\n",
    "\n",
    "# Invoke the agent\n",
    "# This runs the entire graph until it reaches END\n",
    "result = agent.invoke({\"messages\": messages})\n",
    "\n",
    "print(\"\\n[Agent Execution Trace]\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Print all messages in the conversation\n",
    "for i, m in enumerate(result[\"messages\"], 1):\n",
    "    print(f\"\\nMessage {i}:\")\n",
    "    m.pretty_print()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Total LLM calls: {result.get('llm_calls', 'N/A')}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a3031-1ca7-4eaa-ae0e-60a709bb1470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
