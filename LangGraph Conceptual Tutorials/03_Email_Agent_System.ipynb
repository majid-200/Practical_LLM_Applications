{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46058103-b49f-406c-86af-76ef77b769a3",
   "metadata": {},
   "source": [
    "# INTELLIGENT EMAIL AGENT - Automated Customer Support System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a069b536-d2c2-437c-bb12-953abd3e0f9f",
   "metadata": {},
   "source": [
    "    WHAT THIS CODE DOES:\n",
    "    Creates an AI-powered customer support agent that:\n",
    "    1. Reads incoming emails\n",
    "    2. Classifies intent and urgency\n",
    "    3. Searches documentation/creates bug tickets as needed\n",
    "    4. Drafts responses\n",
    "    5. Routes critical emails to humans for review\n",
    "    6. Sends approved replies\n",
    "    \n",
    "    THE BIG PICTURE:\n",
    "    ┌──────────────────────────────────────────────────────────────────────────┐\n",
    "    │                         EMAIL PROCESSING PIPELINE                        │\n",
    "    ├──────────────────────────────────────────────────────────────────────────┤\n",
    "    │                                                                          │\n",
    "    │   Incoming Email                                                         │\n",
    "    │       │                                                                  │\n",
    "    │       ▼                                                                  │\n",
    "    │   Classify (Intent + Urgency)                                            │\n",
    "    │       │                                                                  │\n",
    "    │       ├────► Billing/Critical? ──►  Human Review                         │\n",
    "    │       │                                                                  │\n",
    "    │       ├────► Question/Feature? ──►  Search Docs                          │\n",
    "    │       │                                                                  │\n",
    "    │       └────► Bug? ──────────────►  Create Ticket                         │\n",
    "    │                                                                          │\n",
    "    │   Draft Response                                                         │\n",
    "    │       │                                                                  │\n",
    "    │       ├────► High Priority? ───►  Human Review                           │\n",
    "    │       │                                                                  │\n",
    "    │       └────► Low Priority? ────►  Auto-Send                              │\n",
    "    │                                                                          │\n",
    "    └──────────────────────────────────────────────────────────────────────────┘\n",
    "    \n",
    "    KEY FEATURES:\n",
    "    - Structured output (EmailClassification)\n",
    "    - Dynamic routing based on classification\n",
    "    - Human-in-the-loop for critical issues\n",
    "    - Retry policies for transient failures\n",
    "    - State persistence with checkpointing\n",
    "    - Command pattern for explicit control flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48186df2-f3fa-4cb6-821e-8dd4835dc2e9",
   "metadata": {},
   "source": [
    "## PART 1: Define Data Structures (The \"Schema\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9837bf0e-353d-457b-aa0f-fd95090f0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560953c1-b1bd-4c51-ac38-9285ef345af3",
   "metadata": {},
   "source": [
    "    Structured output from the LLM's classification step.\n",
    "    \n",
    "    This ensures the AI returns data in a predictable format.\n",
    "    \n",
    "    Attributes:\n",
    "        intent: What the customer wants\n",
    "                - \"question\": Needs information\n",
    "                - \"bug\": Reporting a problem\n",
    "                - \"billing\": Payment/subscription issues\n",
    "                - \"feature\": Requesting new functionality\n",
    "                - \"complex\": Needs human attention\n",
    "        \n",
    "        urgency: How quickly we need to respond\n",
    "                 - \"low\": Can wait days\n",
    "                 - \"medium\": Respond within hours\n",
    "                 - \"high\": Respond within 1 hour\n",
    "                 - \"critical\": Immediate response needed\n",
    "        \n",
    "        topic: Short description (e.g., \"password reset\", \"refund request\")\n",
    "        summary: One-sentence summary of the email\n",
    "    \n",
    "    Example:\n",
    "        {\n",
    "            \"intent\": \"billing\",\n",
    "            \"urgency\": \"critical\",\n",
    "            \"topic\": \"double charge\",\n",
    "            \"summary\": \"Customer was charged twice for subscription\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df1f07b8-0a95-45f3-98b9-419137b1f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailClassification(TypedDict):\n",
    "    intent: Literal[\"question\", \"bug\", \"billing\", \"feature\", \"complex\"]\n",
    "    urgency: Literal[\"low\", \"medium\", \"high\", \"critical\"]\n",
    "    topic: str\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e5bd9-0524-4c2a-b11c-6aa2c57ae6a6",
   "metadata": {},
   "source": [
    "    The COMPLETE STATE that flows through the agent graph.\n",
    "    \n",
    "    Think of this as the agent's \"working memory\" - it tracks:\n",
    "    - What email we're processing\n",
    "    - What we've learned about it\n",
    "    - What we've generated\n",
    "    - Where we are in the process\n",
    "    \n",
    "    State Evolution Example:\n",
    "    \n",
    "    Step 1 (Initial):\n",
    "    {\n",
    "        \"email_content\": \"I was charged twice!\",\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": \"email_123\",\n",
    "        \"classification\": None,\n",
    "        \"search_results\": None,\n",
    "        \"customer_history\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "    }\n",
    "    \n",
    "    Step 2 (After Classification):\n",
    "    {\n",
    "        \"email_content\": \"I was charged twice!\",\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": \"email_123\",\n",
    "        \"classification\": {\n",
    "            \"intent\": \"billing\",\n",
    "            \"urgency\": \"critical\",\n",
    "            \"topic\": \"double charge\",\n",
    "            \"summary\": \"Customer charged twice\"\n",
    "        },  ← ADDED\n",
    "        \"search_results\": None,\n",
    "        \"customer_history\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": [...]\n",
    "    }\n",
    "    \n",
    "    Step 3 (After Draft):\n",
    "    {\n",
    "        \"email_content\": \"I was charged twice!\",\n",
    "        \"sender_email\": \"customer@example.com\",\n",
    "        \"email_id\": \"email_123\",\n",
    "        \"classification\": {...},\n",
    "        \"search_results\": None,\n",
    "        \"customer_history\": None,\n",
    "        \"draft_response\": \"We sincerely apologize...\",  ← ADDED\n",
    "        \"messages\": [...]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff415e88-53fb-4a3b-acf4-55921ab31636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailAgentState(TypedDict):\n",
    "    # ─── Raw Email Data ───\n",
    "    email_content: str  # The actual email text\n",
    "    sender_email: str   # Who sent it\n",
    "    email_id: str       # Unique identifier\n",
    "    \n",
    "    # ─── Classification Result ───\n",
    "    classification: EmailClassification | None  # What kind of email is this?\n",
    "    \n",
    "    # ─── External Data ───\n",
    "    search_results: list[str] | None     # Docs from knowledge base\n",
    "    customer_history: dict | None        # CRM data about this customer\n",
    "    \n",
    "    # ─── Generated Content ───\n",
    "    draft_response: str | None           # AI-drafted reply\n",
    "    messages: list[str] | None           # Conversation history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04bb86-3dd3-46a9-88bd-c59cffbd59eb",
   "metadata": {},
   "source": [
    "## PART 2: Advanced LangGraph Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c0069-2c87-40a4-971e-e48d23f8e04c",
   "metadata": {},
   "source": [
    "### CONCEPT 1: Retry Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e15d6-d459-43a1-851a-b5dc574e5b82",
   "metadata": {},
   "source": [
    "    Sometimes nodes fail due to transient issues (network timeout, API rate limit).\n",
    "    RetryPolicy automatically retries failed nodes.\n",
    "    \n",
    "    Visual:\n",
    "        ┌─────────────────────┐\n",
    "        │ search_documentation│ ─── Attempt 1: Timeout \n",
    "        └─────────────────────┘\n",
    "                 │\n",
    "                 ▼ (wait 1 second)\n",
    "        ┌─────────────────────┐\n",
    "        │ search_documentation│ ─── Attempt 2: Timeout \n",
    "        └─────────────────────┘\n",
    "                 │\n",
    "                 ▼ (wait 2 seconds)\n",
    "        ┌─────────────────────┐\n",
    "        │ search_documentation│ ─── Attempt 3: Success \n",
    "        └─────────────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a805b5-5ccf-4459-961c-879517c93fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "# Example: Add retry policy to a node that might fail\n",
    "# workflow.add_node(\n",
    "#     \"search_documentation\",\n",
    "#     search_documentation,\n",
    "#     retry_policy=RetryPolicy(\n",
    "#         max_attempts=3,        # Try up to 3 times\n",
    "#         initial_interval=1.0   # Wait 1 second between retries\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c208f-ff2f-44bd-a01c-3b8605f50c7b",
   "metadata": {},
   "source": [
    "### CONCEPT 2: Command Pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f98e25f-5b3f-4462-ba57-eb73a581e0a2",
   "metadata": {},
   "source": [
    "    The Command pattern gives you EXPLICIT CONTROL over:\n",
    "    1. What data to update in state\n",
    "    2. Which node to go to next\n",
    "    \n",
    "    This replaces implicit routing with explicit decisions.\n",
    "    \n",
    "    Old Way (implicit):\n",
    "        def my_node(state):\n",
    "            return {\"some_data\": \"value\"}  # Where does it go next? \n",
    "    \n",
    "    New Way (explicit):\n",
    "        def my_node(state) -> Command[Literal[\"next_node_a\", \"next_node_b\"]]:\n",
    "            if condition:\n",
    "                return Command(update={\"data\": \"value\"}, goto=\"next_node_a\")\n",
    "            else:\n",
    "                return Command(update={\"data\": \"value\"}, goto=\"next_node_b\")\n",
    "    \n",
    "    Visual Flow with Command:\n",
    "        ┌──────────────┐\n",
    "        │  execute_tool│\n",
    "        └──────┬───────┘\n",
    "               │\n",
    "               ├──► Success? ──► Command(goto=\"agent\")\n",
    "               │\n",
    "               └──► Error? ────► Command(goto=\"agent\", with error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d79c5de-fe49-4143-a488-7dbb3579ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Example: Handle tool execution with error recovery\n",
    "def execute_tool(state) -> Command[Literal[\"agent\", \"execute_tool\"]]:\n",
    "    \"\"\"\n",
    "    Example showing Command pattern with error handling.\n",
    "    \n",
    "    This isn't used in our email agent, but demonstrates the concept.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to run the tool\n",
    "        result = run_tool(state['tool_call'])\n",
    "        \n",
    "        # Success! Update state and go to agent\n",
    "        return Command(\n",
    "            update={\"tool_result\": result},\n",
    "            goto=\"agent\"\n",
    "        )\n",
    "    except ToolError as e:\n",
    "        # Error! Send error message to agent so it can retry\n",
    "        return Command(\n",
    "            update={\"tool_result\": f\"Tool error: {str(e)}\"},\n",
    "            goto=\"agent\"  # Let LLM see the error and decide what to do\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5532f51-f6af-4172-89e2-c3efe2b59dfc",
   "metadata": {},
   "source": [
    "### CONCEPT 3: Human-in-the-Loop with interrupt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2428d3c-e323-4ff2-971a-c59a395bc5e0",
   "metadata": {},
   "source": [
    "    interrupt() PAUSES the graph and waits for human input.\n",
    "    \n",
    "    Flow:\n",
    "        1. Agent processes email\n",
    "        2. Reaches human_review node\n",
    "        3. interrupt() is called → graph PAUSES \n",
    "        4. Human reviews and approves/edits\n",
    "        5. Resume execution with human's decision\n",
    "    \n",
    "    Visual:\n",
    "        ┌───────────────┐\n",
    "        │ draft_response│\n",
    "        └──────┬────────┘\n",
    "               │\n",
    "               ▼\n",
    "        ┌──────────────────────┐\n",
    "        │   human_review       │\n",
    "        │   interrupt()        │ ◄─── PAUSED HERE\n",
    "        └──────────────────────┘\n",
    "               ⋮  (waiting for human)\n",
    "               ⋮\n",
    "        Human provides input ✓\n",
    "               ⋮\n",
    "               ▼\n",
    "        ┌──────────────┐\n",
    "        │  send_reply  │\n",
    "        └──────────────┘\n",
    "    \n",
    "    CRITICAL: Code before interrupt() will RE-RUN when resuming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bcc22b2-430d-448e-a180-a8928408efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import interrupt\n",
    "\n",
    "# Example: Request customer ID from human if missing\n",
    "def lookup_customer_history(state) -> Command[Literal[\"draft_response\", \"lookup_customer_history\"]]:\n",
    "    \"\"\"\n",
    "    Example showing interrupt() for requesting missing information.\n",
    "    \n",
    "    This isn't used in our email agent, but demonstrates the concept.\n",
    "    \"\"\"\n",
    "    if not state.get('customer_id'):\n",
    "        # Pause and ask human for customer ID\n",
    "        user_input = interrupt({\n",
    "            \"message\": \"Customer ID needed\",\n",
    "            \"request\": \"Please provide the customer's account ID to look up their subscription history\"\n",
    "        })\n",
    "        \n",
    "        # When resumed, update state with provided ID\n",
    "        return Command(\n",
    "            update={\"customer_id\": user_input['customer_id']},\n",
    "            goto=\"lookup_customer_history\"  # Try again with the ID\n",
    "        )\n",
    "    \n",
    "    # Now we have the ID, proceed with lookup\n",
    "    customer_data = fetch_customer_history(state['customer_id'])\n",
    "    return Command(\n",
    "        update={\"customer_history\": customer_data},\n",
    "        goto=\"draft_response\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bc05ea-3d7f-484b-a6f3-26324c649d9d",
   "metadata": {},
   "source": [
    "## PART 3: Node Definitions (The Processing Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67e46ff0-fdb0-4c91-aa89-994d633483d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import interrupt, Command, RetryPolicy\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "llm = init_chat_model(\n",
    "    model=\"qwen3:8b\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature=0  # 0 = deterministic, no randomness\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a0e72-2eaa-4f9b-b423-447ca4b65a31",
   "metadata": {},
   "source": [
    "### NODE 1: Read Email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a86a10-31d3-49d9-9607-5c3dd61e46eb",
   "metadata": {},
   "source": [
    "    Entry point: Extract and parse email content.\n",
    "    \n",
    "    In production, this would:\n",
    "    - Connect to email service (Gmail, Outlook, etc.)\n",
    "    - Parse email headers\n",
    "    - Extract attachments\n",
    "    - Clean up formatting\n",
    "    \n",
    "    For now, just acknowledges the email in messages.\n",
    "    \n",
    "    Flow:\n",
    "        Input State: {email_content: \"...\", sender_email: \"...\", ...}\n",
    "        ↓\n",
    "        Output: {messages: [HumanMessage(\"Processing email: ...\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b76a827e-5a30-40bc-9d1c-43ba846b58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(state: EmailAgentState) -> dict:\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=f\"Processing email: {state['email_content']}\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ccccc2-1c47-4e16-bdc5-833610de4586",
   "metadata": {},
   "source": [
    "### NODE 2: Classify Intent (The Router)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7981130b-d30a-4a19-b475-eb6a2213d3c8",
   "metadata": {},
   "source": [
    "    Uses LLM to classify the email and route it appropriately.\n",
    "    \n",
    "    This is the BRAIN of the system - it decides where emails go.\n",
    "    \n",
    "    Process:\n",
    "    ┌─────────────────────────────────────────────────────────────────────┐\n",
    "    │ 1. Take email content                                               │\n",
    "    │ 2. Ask LLM to classify (intent, urgency, topic, summary)            │\n",
    "    │ 3. Based on classification, decide which node to visit next         │\n",
    "    └─────────────────────────────────────────────────────────────────────┘\n",
    "    \n",
    "    Routing Logic:\n",
    "        Intent: billing OR Urgency: critical\n",
    "            → human_review (humans handle money issues!)\n",
    "        \n",
    "        Intent: question OR feature\n",
    "            → search_documentation (look up answer)\n",
    "        \n",
    "        Intent: bug\n",
    "            → bug_tracking (create ticket)\n",
    "        \n",
    "        Otherwise\n",
    "            → draft_response (generate reply directly)\n",
    "    \n",
    "    Args:\n",
    "        state: Current email state\n",
    "        \n",
    "    Returns:\n",
    "        Command with classification data and next node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e71e4f3-ee54-4981-a0ab-cff3f8d5fcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_intent(state: EmailAgentState) -> Command[Literal[\"search_documentation\", \"human_review\", \"draft_response\", \"bug_tracking\"]]:\n",
    "    # Create a version of the LLM that returns structured data\n",
    "    # This ensures we get a dict matching EmailClassification\n",
    "    structured_llm = llm.with_structured_output(EmailClassification)\n",
    "    \n",
    "    # Build the classification prompt\n",
    "    classification_prompt = f\"\"\"\n",
    "    Analyze this customer email and classify it:\n",
    "    Email: {state['email_content']}\n",
    "    From: {state['sender_email']}\n",
    "    \n",
    "    Provide classification including intent, urgency, topic, and summary.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get classification from LLM\n",
    "    # Result is guaranteed to match EmailClassification structure\n",
    "    classification = structured_llm.invoke(classification_prompt)\n",
    "    \n",
    "    # ─── Routing Logic ───\n",
    "    # Decide which node to go to based on classification\n",
    "    \n",
    "    if classification['intent'] == 'billing' or classification['urgency'] == 'critical':\n",
    "        # Money matters and emergencies need human attention\n",
    "        goto = \"human_review\"\n",
    "        \n",
    "    elif classification['intent'] in ['question', 'feature']:\n",
    "        # Questions and feature requests need documentation\n",
    "        goto = \"search_documentation\"\n",
    "        \n",
    "    elif classification['intent'] == 'bug':\n",
    "        # Bugs need tickets\n",
    "        goto = \"bug_tracking\"\n",
    "        \n",
    "    else:\n",
    "        # Everything else can be drafted directly\n",
    "        goto = \"draft_response\"\n",
    "    \n",
    "    # Return Command with classification and routing decision\n",
    "    return Command(\n",
    "        update={\"classification\": classification},\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e18ac55-c331-4864-8ad2-83d79bb47e30",
   "metadata": {},
   "source": [
    "### NODE 3: Search Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da2739-233f-45ea-8eaa-4b7ecdcdaad7",
   "metadata": {},
   "source": [
    "    Search knowledge base for relevant information.\n",
    "    \n",
    "    This node:\n",
    "    1. Extracts search query from classification\n",
    "    2. Queries documentation/knowledge base\n",
    "    3. Returns relevant chunks\n",
    "    4. Handles search failures gracefully\n",
    "    \n",
    "    In production, this would:\n",
    "    - Use vector database (Pinecone, Weaviate)\n",
    "    - Semantic search with embeddings\n",
    "    - Rank results by relevance\n",
    "    \n",
    "    Error Handling:\n",
    "    - If search fails (network issue, API down), store error message\n",
    "    - Don't crash the whole pipeline\n",
    "    - Let draft_response handle the missing data\n",
    "    \n",
    "    Args:\n",
    "        state: Contains classification with intent and topic\n",
    "        \n",
    "    Returns:\n",
    "        Command with search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "858123c6-561a-4268-b158-b4ddd1da4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documentation(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    # Build search query from classification\n",
    "    classification = state.get('classification', {})\n",
    "    query = f\"{classification.get('intent', '')} {classification.get('topic', '')}\"\n",
    "    \n",
    "    try:\n",
    "        # In production: search_api.query(query)\n",
    "        # For demo, return hardcoded results\n",
    "        search_results = [\n",
    "            \"Reset password via Settings > Security > Change Password\",\n",
    "            \"Password must be at least 12 characters\",\n",
    "            \"Include uppercase, lowercase, numbers, and symbols\"\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        # Graceful degradation: store error instead of crashing\n",
    "        search_results = [f\"Search temporarily unavailable: {str(e)}\"]\n",
    "    \n",
    "    return Command(\n",
    "        update={\"search_results\": search_results},\n",
    "        goto=\"draft_response\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5c323d-b0cf-4d84-974b-dcfdd27a4e78",
   "metadata": {},
   "source": [
    "### NODE 4: Bug Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aefa3fe-b9ad-455f-a751-31658a4b5e9e",
   "metadata": {},
   "source": [
    "    Create bug tracking ticket for reported issues.\n",
    "    \n",
    "    In production, this would:\n",
    "    - Create Jira/Linear/GitHub issue\n",
    "    - Extract relevant details (steps to reproduce, environment)\n",
    "    - Assign to appropriate team\n",
    "    - Set priority based on urgency\n",
    "    \n",
    "    Args:\n",
    "        state: Contains email content and classification\n",
    "        \n",
    "    Returns:\n",
    "        Command with ticket information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b48766f3-cfbb-4df9-9dc6-f0e92ed8dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bug_tracking(state: EmailAgentState) -> Command[Literal[\"draft_response\"]]:\n",
    "    # In production: jira_api.create_issue(...)\n",
    "    ticket_id = \"BUG-12345\"\n",
    "    \n",
    "    return Command(\n",
    "        update={\"search_results\": [f\"Bug ticket {ticket_id} created\"]},\n",
    "        goto=\"draft_response\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b01b-94a3-446b-8b36-946d284b7bfb",
   "metadata": {},
   "source": [
    "### NODE 5: Draft Response (The Writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd8a7c-6638-4753-b68c-8b25a289e415",
   "metadata": {},
   "source": [
    "    Generate email response using all available context.\n",
    "    \n",
    "    This node:\n",
    "    1. Gathers all context (classification, search results, customer history)\n",
    "    2. Formats it into a prompt\n",
    "    3. Asks LLM to draft a response\n",
    "    4. Decides if human review is needed\n",
    "    \n",
    "    Context Assembly:\n",
    "    ┌────────────────────────────────────────────────┐\n",
    "    │ Classification: {intent, urgency, topic}       │\n",
    "    │ Search Results: [doc1, doc2, doc3]             │\n",
    "    │ Customer History: {tier, subscription, ...}    │\n",
    "    └─────────────────┬──────────────────────────────┘\n",
    "                      │\n",
    "                      ▼\n",
    "    ┌────────────────────────────────────────────────┐\n",
    "    │  Formatted Prompt for LLM                      │\n",
    "    └─────────────────┬──────────────────────────────┘\n",
    "                      │\n",
    "                      ▼\n",
    "    ┌────────────────────────────────────────────────┐\n",
    "    │  LLM Generates Draft Response                  │\n",
    "    └────────────────────────────────────────────────┘\n",
    "    \n",
    "    Routing Decision:\n",
    "    - High/Critical urgency → human_review\n",
    "    - Complex intent → human_review  \n",
    "    - Otherwise → send_reply\n",
    "    \n",
    "    Args:\n",
    "        state: Complete state with all context\n",
    "        \n",
    "    Returns:\n",
    "        Command with draft response and routing decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f3362f-9af5-403d-be2f-2d9fe67081f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draft_response(state: EmailAgentState) -> Command[Literal[\"human_review\", \"send_reply\"]]:\n",
    "    classification = state.get('classification', {})\n",
    "    \n",
    "    # ─── Format Context Sections ───\n",
    "    # Build context dynamically from available data\n",
    "    context_sections = []\n",
    "    \n",
    "    if state.get('search_results'):\n",
    "        # Format search results as bullet points\n",
    "        formatted_docs = \"\\n\".join([f\"- {doc}\" for doc in state['search_results']])\n",
    "        context_sections.append(f\"Relevant documentation:\\n{formatted_docs}\")\n",
    "    \n",
    "    if state.get('customer_history'):\n",
    "        # Add customer information\n",
    "        context_sections.append(\n",
    "            f\"Customer tier: {state['customer_history'].get('tier', 'standard')}\"\n",
    "        )\n",
    "    \n",
    "    # ─── Build the Prompt ───\n",
    "    draft_prompt = f\"\"\"\n",
    "    Draft a response to this customer email:\n",
    "    \n",
    "    {state['email_content']}\n",
    "    \n",
    "    Email intent: {classification.get('intent', 'unknown')}\n",
    "    Urgency level: {classification.get('urgency', 'medium')}\n",
    "    \n",
    "    {chr(10).join(context_sections)}\n",
    "    \n",
    "    Guidelines:\n",
    "    - Be professional and helpful\n",
    "    - Address their specific concern\n",
    "    - Use the provided documentation when relevant\n",
    "    \"\"\"\n",
    "    \n",
    "    # ─── Generate Response ───\n",
    "    response = llm.invoke(draft_prompt)\n",
    "    \n",
    "    # ─── Decide if Human Review Needed ───\n",
    "    needs_review = (\n",
    "        classification.get('urgency') in ['high', 'critical'] or\n",
    "        classification.get('intent') == 'complex'\n",
    "    )\n",
    "    \n",
    "    goto = \"human_review\" if needs_review else \"send_reply\"\n",
    "    \n",
    "    return Command(\n",
    "        update={\"draft_response\": response.content},\n",
    "        goto=goto\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6def7-ecd3-4d74-921a-081a8fabac5c",
   "metadata": {},
   "source": [
    "### NODE 6: Human Review (The Checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941c8cf-78a1-4f8c-9db2-243bae89b572",
   "metadata": {},
   "source": [
    "    Pause for human review and approval.\n",
    "    \n",
    "    This is the HUMAN-IN-THE-LOOP checkpoint.\n",
    "    \n",
    "    Flow:\n",
    "    1. Graph reaches this node\n",
    "    2. interrupt() PAUSES execution \n",
    "    3. Human reviews the draft\n",
    "    4. Human approves/edits/rejects\n",
    "    5. Graph RESUMES with human's decision\n",
    "    \n",
    "    Critical Implementation Detail:\n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "    interrupt() MUST come first!\n",
    "    \n",
    "    Any code BEFORE interrupt() will RE-RUN when resuming.\n",
    "    Any code AFTER interrupt() runs only once (after human input).\n",
    "    ═══════════════════════════════════════════════════════════════\n",
    "    \n",
    "    Visualization:\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │ First Execution (up to interrupt):                          │\n",
    "    │                                                             │\n",
    "    │ classification = state.get('classification', {})            │\n",
    "    │ human_decision = interrupt({...}) ← PAUSES HERE             │\n",
    "    │                                                             │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "              ⋮\n",
    "              ⋮ (waiting for human)\n",
    "              ⋮\n",
    "    ┌─────────────────────────────────────────────────────────────┐\n",
    "    │ Second Execution (after resume):                            │\n",
    "    │                                                             │\n",
    "    │ classification = state.get('classification', {})  ← RE-RUNS │\n",
    "    │ human_decision = interrupt({...}) ← Returns human input     │\n",
    "    │ if human_decision.get(\"approved\"): ← Runs for first time    │\n",
    "    │     ...                                                     │\n",
    "    └─────────────────────────────────────────────────────────────┘\n",
    "    \n",
    "    Args:\n",
    "        state: Contains draft response and classification\n",
    "        \n",
    "    Returns:\n",
    "        Command based on human decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3017c93d-dfd1-4ed5-ac8e-7b09ebd03012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_review(state: EmailAgentState) -> Command[Literal[\"send_reply\", END]]:\n",
    "    classification = state.get('classification', {})\n",
    "    \n",
    "    # CRITICAL: interrupt() MUST BE FIRST\n",
    "    \n",
    "    # Pause and wait for human input\n",
    "    human_decision = interrupt({\n",
    "        \"email_id\": state.get('email_id', ''),\n",
    "        \"original_email\": state.get('email_content', ''),\n",
    "        \"draft_response\": state.get('draft_response', ''),\n",
    "        \"urgency\": classification.get('urgency'),\n",
    "        \"intent\": classification.get('intent'),\n",
    "        \"action\": \"Please review and approve/edit this response\"\n",
    "    })\n",
    "    \n",
    "    # ─── Process Human Decision ───\n",
    "    # This code runs AFTER human provides input\n",
    "    \n",
    "    if human_decision.get(\"approved\"):\n",
    "        # Human approved (possibly with edits)\n",
    "        return Command(\n",
    "            update={\n",
    "                \"draft_response\": human_decision.get(\n",
    "                    \"edited_response\", \n",
    "                    state.get('draft_response', '')\n",
    "                )\n",
    "            },\n",
    "            goto=\"send_reply\"\n",
    "        )\n",
    "    else:\n",
    "        # Human rejected - they'll handle it manually\n",
    "        return Command(update={}, goto=END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c5fb3-fcf7-411b-8d53-1065108c661d",
   "metadata": {},
   "source": [
    "### NODE 7: Send Reply (The Finisher)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cd7cc4-8b1b-46d1-9d05-47871b760867",
   "metadata": {},
   "source": [
    "    Send the approved email response.\n",
    "    \n",
    "    In production, this would:\n",
    "    - Connect to email service API\n",
    "    - Format email with proper headers\n",
    "    - Track sent emails\n",
    "    - Log for auditing\n",
    "    \n",
    "    Error Handling:\n",
    "    - Let unexpected errors bubble up (they're serious)\n",
    "    - Retry logic should be at infrastructure level\n",
    "    \n",
    "    Args:\n",
    "        state: Contains final draft_response\n",
    "        \n",
    "    Returns:\n",
    "        Empty dict (end of pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d1afdcb-1dc6-40f4-95da-45db0f4c404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_reply(state: EmailAgentState) -> dict:\n",
    "    # In production: email_service.send(to=state['sender_email'], body=state['draft_response'])\n",
    "    print(f\"Sending reply: {state['draft_response'][:100]}...\")\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c49c194-4ba0-4e35-8417-cf27cb599efa",
   "metadata": {},
   "source": [
    "## PART 4: Build the Agent Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aec682b-1e44-4d8a-acbe-e895a9c563ff",
   "metadata": {},
   "source": [
    "    GRAPH STRUCTURE:\n",
    "    ════════════════════════════════════════════════════════════════════════════\n",
    "    \n",
    "                                  START\n",
    "                                    │\n",
    "                                    ▼\n",
    "                             ┌─────────────┐\n",
    "                             │ read_email  │\n",
    "                             └──────┬──────┘\n",
    "                                    │\n",
    "                                    ▼\n",
    "                        ┌───────────────────────┐\n",
    "                        │   classify_intent     │\n",
    "                        └───────────┬───────────┘\n",
    "                                    │\n",
    "                        ┌───────────┼───────────┬───────────┐\n",
    "                        │           │           │           │\n",
    "                        ▼           ▼           ▼           ▼\n",
    "              ┌─────────────┐ ┌────────┐ ┌─────────┐ ┌────────────┐\n",
    "              │   search    │ │  bug   │ │  draft  │ │   human    │\n",
    "              │documentation│ │tracking│ │response │ │  review    │\n",
    "              └──────┬──────┘ └───┬────┘ └────┬────┘ └─────┬──────┘\n",
    "                     │            │           │            │\n",
    "                     └────────────┴──────► draft_response  │\n",
    "                                            │              │\n",
    "                                       ┌────┴────┐         │\n",
    "                                       ▼         ▼         │\n",
    "                                ┌────────────┐ ┌────────────┐\n",
    "                                │   send     │ │   human    │\n",
    "                                │   reply    │ │  review    │\n",
    "                                └──────┬─────┘ └─────┬──────┘\n",
    "                                       │             │\n",
    "                                       ├─────────────┤\n",
    "                                       │             │\n",
    "                                       ▼             ▼\n",
    "                                     END           send_reply\n",
    "                                                     │\n",
    "                                                     ▼\n",
    "                                                   END\n",
    "    \n",
    "    Key Features:\n",
    "    - Multiple routing paths from classify_intent\n",
    "    - Conditional routing from draft_response\n",
    "    - Human review can go to send_reply OR END\n",
    "    - Retry policy on search_documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "628be96f-b560-46ea-85fd-d6e82f018de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.types import RetryPolicy\n",
    "\n",
    "# Create the graph\n",
    "workflow = StateGraph(EmailAgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7e4fb-bb4c-4b32-8085-2dbb61d08a9c",
   "metadata": {},
   "source": [
    "### Add Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80a6bd2e-3193-437f-94c0-4d45610f813c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a9b9759ca0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"read_email\", read_email)\n",
    "workflow.add_node(\"classify_intent\", classify_intent)\n",
    "\n",
    "# Add retry policy for nodes that might have transient failures\n",
    "workflow.add_node(\n",
    "    \"search_documentation\",\n",
    "    search_documentation,\n",
    "    retry_policy=RetryPolicy(max_attempts=3)  # Retry up to 3 times\n",
    ")\n",
    "\n",
    "workflow.add_node(\"bug_tracking\", bug_tracking)\n",
    "workflow.add_node(\"draft_response\", draft_response)\n",
    "workflow.add_node(\"human_review\", human_review)\n",
    "workflow.add_node(\"send_reply\", send_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776077c-d467-4cfc-b950-baf786c0f74c",
   "metadata": {},
   "source": [
    "### Add Edges (Only the non-conditional ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c7e757e-f1df-46d4-a050-21ac50fa7919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a9b9759ca0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixed edges that always happen\n",
    "workflow.add_edge(START, \"read_email\")\n",
    "workflow.add_edge(\"read_email\", \"classify_intent\")\n",
    "workflow.add_edge(\"send_reply\", END)\n",
    "\n",
    "# Note: Conditional edges are handled by Command.goto in the node functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a08aac-4fa0-4e69-af42-33435d922bfe",
   "metadata": {},
   "source": [
    "### Compile with Checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63078f-3ee1-4156-ab7a-c8ccba93d6ba",
   "metadata": {},
   "source": [
    "    Checkpointer enables:\n",
    "    1. State Persistence: Save state between runs\n",
    "    2. Resume Capability: Continue from where you left off\n",
    "    3. Time Travel: Go back to previous states\n",
    "    4. Human-in-the-Loop: Essential for interrupt() to work\n",
    "    \n",
    "    Without checkpointer: interrupt() won't work (no way to resume)\n",
    "    With checkpointer: Can pause and resume execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a485d26-45a7-42a1-b1de-fd942c54ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()  # In-memory checkpointer (use Redis/Postgres in production)\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2250d2-8491-4f3c-8c52-5aca0b7e47dc",
   "metadata": {},
   "source": [
    "## PART 5: Run the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffbd57c-097f-4bad-8c56-44776e618d74",
   "metadata": {},
   "source": [
    "### STEP 1: Create Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21d1915c-1772-41e8-a9af-f49a8be68061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Initial Email]\n",
      "From: customer@example.com\n",
      "Content: I was charged twice for my subscription! This is urgent!\n"
     ]
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"email_content\": \"I was charged twice for my subscription! This is urgent!\",\n",
    "    \"sender_email\": \"customer@example.com\",\n",
    "    \"email_id\": \"email_123\",\n",
    "    \"messages\": []\n",
    "}\n",
    "\n",
    "# Config with thread_id for persistence\n",
    "# The thread_id groups related executions together\n",
    "config = {\"configurable\": {\"thread_id\": \"customer_123\"}}\n",
    "\n",
    "print(\"\\n[Initial Email]\")\n",
    "print(f\"From: {initial_state['sender_email']}\")\n",
    "print(f\"Content: {initial_state['email_content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6f9444-03fa-4358-9de8-abde299a70fb",
   "metadata": {},
   "source": [
    "### STEP 2: First Invocation (Will Pause at Human Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413be5b-27ba-44b2-8ed4-881857718a0a",
   "metadata": {},
   "source": [
    "    Execution Trace:\n",
    "    1. START → read_email\n",
    "       - Acknowledges email\n",
    "       \n",
    "    2. read_email → classify_intent\n",
    "       - LLM classifies: intent=\"billing\", urgency=\"critical\"\n",
    "       - Routes to human_review (billing + critical = human needed!)\n",
    "       \n",
    "    3. classify_intent → human_review\n",
    "       - Generates draft response\n",
    "       - interrupt() is called → PAUSES \n",
    "       \n",
    "    Graph is now WAITING for human input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "914c87f5-2910-4f94-9a1e-41b4086c3b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Starting Agent...]\n",
      "\n",
      "[Agent Paused at Human Review]\n",
      "Draft ready for review: <think>\n",
      "Okay, the user received a customer email about being charged twice for their subscription and it's urgent. Let me start by understanding the situation. The customer is upset and needs a quick resolution. The guidelines say to be professional, address their concern, and use documentation if needed.\n",
      "\n",
      "First, I should acknowledge their urgency and apologize for the inconvenience. It's important to show empathy. Then, I need to ask for their subscription details to identify the charges. Maybe mention that I can check the billing history. Also, offer to refund the duplicate charge once confirmed. I should keep the tone calm and reassuring, making sure they feel supported. Let me structure the response step by step: start with a greeting, express regret, request necessary info, explain the next steps, offer a refund, and close with contact info. Make sure it's clear and concise without any jargon. Check if there's any documentation to reference, but since none was provided, just stick to standard procedures. Avoid making promises that can't be kept, so keep the refund offer conditional on verification. Alright, that should cover it.\n",
      "</think>\n",
      "\n",
      "**Subject:** Immediate Action on Duplicate Subscription Charge  \n",
      "\n",
      "Dear [Customer's Name],  \n",
      "\n",
      "Thank you for reaching out, and I sincerely apologize for the inconvenience caused by the duplicate charge. We understand how frustrating this must be, and we’re here to resolve this urgently.  \n",
      "\n",
      "To expedite the process, could you please provide the following details?  \n",
      "1. Your subscription email address or account username.  \n",
      "2. The dates and amounts of the duplicate charges.  \n",
      "3. Any confirmation numbers or transaction IDs associated with the charges.  \n",
      "\n",
      "Once we have this information, our team will:  \n",
      "- Investigate the duplicate charge immediately.  \n",
      "- Verify if it was a billing error or a duplicate payment.  \n",
      "- Issue a refund for the duplicate amount within [X business days] once confirmed.  \n",
      "\n",
      "If you’re unsure about the details, please let us know, and we’ll guide you through the process. Your satisfaction is our priority, and we’ll ensure this is resolved swiftly.  \n",
      "\n",
      "Thank you for your patience. If you have any further questions, please reply to this email or contact our support team at [support email/phone number].  \n",
      "\n",
      "Best regards,  \n",
      "[Your Full Name]  \n",
      "[Your Job Title]  \n",
      "[Company Name]  \n",
      "[Contact Information]  \n",
      "\n",
      "---  \n",
      "*Note: This response balances urgency with professionalism, requests critical details for resolution, and reassures the customer of a prompt refund once verified.*\n",
      "Classification: {'intent': 'complex', 'urgency': 'high', 'topic': 'billing', 'summary': 'Customer was charged twice for their subscription and is requesting urgent assistance.'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Starting Agent...]\")\n",
    "result = app.invoke(initial_state, config)\n",
    "\n",
    "print(\"\\n[Agent Paused at Human Review]\")\n",
    "print(f\"Draft ready for review: {result['draft_response']}\")\n",
    "print(f\"Classification: {result['classification']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b5bf9-d890-433a-8818-2aeb389f50f1",
   "metadata": {},
   "source": [
    "### STEP 3: Human Provides Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f40df9a-b78a-4b7f-8b70-b466fe563d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Human reviewing and editing draft...]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Human reviewing and editing draft...]\")\n",
    "\n",
    "# Simulate human approval with edits\n",
    "from langgraph.types import Command\n",
    "\n",
    "human_response = Command(\n",
    "    resume={\n",
    "        \"approved\": True,\n",
    "        \"edited_response\": \"We sincerely apologize for the double charge. I've initiated an immediate refund that should appear in your account within 3-5 business days. As a gesture of goodwill, we've also added a month of free service to your account. If you have any other concerns, please don't hesitate to reach out.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea5c3dd-3a94-4d39-8d2f-e97bc73558d9",
   "metadata": {},
   "source": [
    "### STEP 4: Resume Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf56942-f4bb-46a4-9a5c-64d4b3cda0d4",
   "metadata": {},
   "source": [
    "    Continued Execution:\n",
    "    4. human_review (resumed)\n",
    "       - Processes human's approval\n",
    "       - Updates draft with edited version\n",
    "       - Routes to send_reply\n",
    "       \n",
    "    5. send_reply → END\n",
    "       - Sends the email\n",
    "       - Workflow complete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "630d9949-a96a-428c-8d78-b19838d9ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Resuming agent with human approval...]\n",
      "\n",
      "[Email sent successfully!]\n",
      "Final response (first 200 chars):\n",
      "We sincerely apologize for the double charge. I've initiated an immediate refund that should appear in your account within 3-5 business days. As a gesture of goodwill, we've also added a month of free...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[Resuming agent with human approval...]\")\n",
    "\n",
    "# Resume with the same config (same thread_id)\n",
    "final_result = app.invoke(human_response, config)\n",
    "\n",
    "print(f\"\\n[Email sent successfully!]\")\n",
    "print(f\"Final response (first 200 chars):\")\n",
    "print(f\"{final_result.get('draft_response', '')[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0829b2f7-5e1d-48b1-ae44-6fe9ca81247e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
