{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4dcb99-0330-4f65-a9fc-4210cf18abf9",
   "metadata": {},
   "source": [
    "# LANGGRAPH BASICS - Building a Simple AI Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228adf0-f329-4d33-8eac-df123fcb01ee",
   "metadata": {},
   "source": [
    "LangGraph is a library for building STATEFUL, MULTI-STEP workflows with LLMs.\n",
    "\n",
    "Think of it as building a flowchart where:\n",
    "- Each box is a \"node\" (a function that does something)\n",
    "- Arrows are \"edges\" (connections between nodes)\n",
    "- Data flows through the graph like water through pipes\n",
    "\n",
    "WHAT THIS CODE DOES:\n",
    "\n",
    "Takes a user message → Processes it through mock_llm → Returns AI response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c36418-163c-4a65-b5a1-3f0dfbf85d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START, END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c5729-6d69-41da-a3ae-1575d369a77d",
   "metadata": {},
   "source": [
    "## STEP 1: Define a Node Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de563281-37d3-4511-9cc1-d022586c7365",
   "metadata": {},
   "source": [
    "    A NODE is a function that:\n",
    "    1. Receives the current state (conversation history)\n",
    "    2. Does some processing\n",
    "    3. Returns updated state\n",
    "    \n",
    "    This is a \"mock\" LLM - it doesn't actually call an AI model,\n",
    "    it just returns a hardcoded response.\n",
    "    \n",
    "    Args:\n",
    "        state: MessagesState - Contains conversation history\n",
    "               Format: {\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}, ...]}\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with new messages to ADD to the state\n",
    "        \n",
    "    Visual Flow:\n",
    "        ┌─────────────────────┐\n",
    "        │  Input State        │\n",
    "        │  messages: [        │\n",
    "        │    {user: \"hi!\"}    │\n",
    "        │  ]                  │\n",
    "        └──────────┬──────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "        ┌─────────────────────┐\n",
    "        │  mock_llm()         │\n",
    "        │  Generates response │\n",
    "        └──────────┬──────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "        ┌─────────────────────┐\n",
    "        │  Output State       │\n",
    "        │  messages: [        │\n",
    "        │    {user: \"hi!\"},   │\n",
    "        │    {ai: \"hello\"}    │ ← New message added!\n",
    "        │  ]                  │\n",
    "        └─────────────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e13ef8-6729-4ca6-a12a-f30a44833c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mock_llm(state: MessagesState):\n",
    "    return {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404205ee-7c33-4a9e-b72b-90ffafbd5aa3",
   "metadata": {},
   "source": [
    "## STEP 2: Create the Graph Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c175e0-a811-4f2a-846e-750cec27085f",
   "metadata": {},
   "source": [
    "Initialize an empty graph that will track MessagesState\n",
    "\n",
    "MessagesState is a built-in state type that stores conversation messages\n",
    "\n",
    "At this point, the graph looks like:\n",
    "\n",
    "    (empty - no nodes or edges yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f125c965-1a2c-407d-8964-942b18cdf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1cce74-7e2e-4533-b11f-3abd961d5a77",
   "metadata": {},
   "source": [
    "## STEP 3: Add Nodes (The \"Boxes\" in Your Flowchart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305120e-879f-4f9f-a2dd-a2da97e0536b",
   "metadata": {},
   "source": [
    "Adds the mock_llm function as a node named \"mock_llm\"\n",
    "(By default, the node name is the function name)\n",
    "\n",
    "Now the graph looks like:\n",
    "\n",
    "    ┌─────────────┐\n",
    "    │  mock_llm   │  (isolated - not connected yet)\n",
    "    └─────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e82c493-ec7b-4005-a937-cf766e484835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x18ca6bfac60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(mock_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674048b9-1b8c-4dd0-983f-8462a32039c3",
   "metadata": {},
   "source": [
    "## STEP 4: Add Edges (The \"Arrows\" Connecting Nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467b08-57a7-45e1-b31a-2d531e9c7235",
   "metadata": {},
   "source": [
    "START is a special built-in node representing the entry point.\n",
    "\n",
    "This creates an arrow: START → mock_llm\n",
    "\n",
    "Visual:\n",
    "\n",
    "    ┌───────┐         ┌─────────────┐\n",
    "    │ START │ ──────► │  mock_llm   │\n",
    "    └───────┘         └─────────────┘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223e8952-c410-47b7-b526-023e1e043376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x18ca6bfac60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(START, \"mock_llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3becddc1-cdcd-4bd3-ba66-b033a65bf170",
   "metadata": {},
   "source": [
    "END is a special built-in node representing the exit point.\n",
    "\n",
    "This creates an arrow: mock_llm → END\n",
    "\n",
    "Complete Flow:\n",
    "\n",
    "    ┌───────┐         ┌─────────────┐         ┌─────┐\n",
    "    │ START │ ──────► │  mock_llm   │ ──────► │ END │\n",
    "    └───────┘         └─────────────┘         └─────┘\n",
    "    \n",
    "This means:\n",
    "1. Execution starts at START\n",
    "2. Flows to mock_llm (which processes the message)\n",
    "3. Ends at END (returns the final state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee8ac46-01a6-4f18-a4e1-6a1f18fdb3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x18ca6bfac60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(\"mock_llm\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec15866-8520-45f5-a0fd-b226c8b4af70",
   "metadata": {},
   "source": [
    "## STEP 5: Compile the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab4576d-e389-466b-8514-9a238e58ad95",
   "metadata": {},
   "source": [
    ".compile() turns the graph definition into an executable workflow.\n",
    "\n",
    "Think of it like:\n",
    "- Before compile: You have a blueprint/recipe\n",
    "- After compile: You have a working machine\n",
    "\n",
    "The compiled graph can now be invoked (run) with input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552d3e47-b58f-49fa-b201-fc82782d9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5924a5f3-5f4c-4e67-b7d7-2a22422938e3",
   "metadata": {},
   "source": [
    "## STEP 6: Run the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd67d350-2988-4c38-8708-3725b9d01098",
   "metadata": {},
   "source": [
    ".invoke() executes the graph with input data.\n",
    "\n",
    "EXECUTION FLOW:\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "Step 1: START\n",
    "\n",
    "    Initial State:\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"hi!\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "Step 2: mock_llm node\n",
    "\n",
    "    - Receives the state\n",
    "    - Returns: {\"messages\": [{\"role\": \"ai\", \"content\": \"hello world\"}]}\n",
    "    - LangGraph APPENDS this to existing messages\n",
    "    \n",
    "    Updated State:\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"hi!\"},\n",
    "            {\"role\": \"ai\", \"content\": \"hello world\"}  ← Added!\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "Step 3: END\n",
    "\n",
    "    Returns final state\n",
    "    \n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "\n",
    "RESULT:\n",
    "\n",
    "{\n",
    "\n",
    "    \"messages\":[\n",
    "        {\"role\": \"user\", \"content\": \"hi!\"},\n",
    "        {\"role\": \"ai\", \"content\": \"hello world\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89254486-c188-4b18-b67e-37506b41e3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='7a9cb050-b99e-44ab-a3ec-3944fd669dac'),\n",
       "  AIMessage(content='hello world', additional_kwargs={}, response_metadata={}, id='e1d17368-684d-4eb1-8625-b85ddaa40297')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"hi!\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5504509d-9eb5-4bcb-9c07-90353c398ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
