{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b4c4a3-f1ec-47a9-a5c8-242ffaa2e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "model = ChatOllama(\n",
    "    model = \"qwen3\",\n",
    "    temperature = 0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44352e40-faaa-441d-80b9-8a7b1d41d9d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\nOkay, the user introduced themselves as Majid. I should respond warmly and ask how I can assist them. Let me make sure to use a friendly tone and keep the conversation open for them to share more about their needs or questions. I should also check if there's anything specific they want help with, like information, advice, or just casual chat. Keeping it welcoming and approachable is key here.\\n</think>\\n\\nHello, Majid! It's nice to meet you. How can I assist you today? Are you looking for information, advice, or just someone to chat with? üòä\", additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-08-04T23:15:23.7164186Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2541912700, 'load_duration': 30593200, 'prompt_eval_count': 14, 'prompt_eval_duration': 122220900, 'eval_count': 122, 'eval_duration': 2387610000, 'model_name': 'qwen3'}, id='run--fdacfbc9-c0ba-4b5c-93fd-07780b909c02-0', usage_metadata={'input_tokens': 14, 'output_tokens': 122, 'total_tokens': 136})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi! I'm Majid\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d69bde3-e0c0-48c5-9ab0-7312b4ff23b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user is asking, \"What\\'s my name?\" I need to figure out how to respond. First, I should check if there\\'s any context from previous interactions. Since this is the first message, there\\'s no prior conversation. The user might be testing if I can recognize their name, but I don\\'t have access to that information unless they provided it earlier.\\n\\nWait, maybe they expect me to know their name from some other source. But according to the guidelines, I can\\'t access personal data or external information. So I should inform them that I don\\'t have access to their name. However, I should also offer to help with anything else they need. Let me make sure the response is polite and clear. I should avoid any assumptions and keep it straightforward. Yeah, that should cover it.\\n</think>\\n\\nI don\\'t have access to personal information about you, including your name. However, I\\'m here to help with any questions or tasks you might have! How can I assist you today? üòä', additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-08-04T23:15:27.7103955Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3984383900, 'load_duration': 28250700, 'prompt_eval_count': 13, 'prompt_eval_duration': 13948400, 'eval_count': 209, 'eval_duration': 3941180600, 'model_name': 'qwen3'}, id='run--bc5613d8-8c85-4513-8057-491eec71f17c-0', usage_metadata={'input_tokens': 13, 'output_tokens': 209, 'total_tokens': 222})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"What's my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6341399-cbc0-42d3-b91a-4a751bab0b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user asked, \"What\\'s my name?\" after I greeted them as \"majid.\" Let me check the conversation history.\\n\\nIn the first message, the user said, \"Hi! I\\'m majid.\" Then I responded with, \"Hello majid! How can I assist you today?\" So I used their name in the greeting. Now, when they ask, \"What\\'s my name?\" they might be confused or testing if I remember their name from the previous message.\\n\\nI need to confirm their name again. Since I already used \"majid\" in the greeting, it\\'s likely they are referring to themselves. But maybe they want to make sure I remember or they might have a different name. Wait, in the initial message, they introduced themselves as \"majid,\" so that\\'s their name. The user might be checking if I recall their name correctly. \\n\\nI should respond by confirming their name and offering further assistance. Let me make sure there\\'s no confusion. The user might be testing the AI\\'s ability to retain information from the conversation. So, the answer should be straightforward, reaffirming their name and asking how I can help. That way, it\\'s clear and helpful.\\n</think>\\n\\nYour name is Majid! üòä How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-08-04T23:15:32.7957582Z', 'done': True, 'done_reason': 'stop', 'total_duration': 5078063600, 'load_duration': 26217300, 'prompt_eval_count': 40, 'prompt_eval_duration': 15170500, 'eval_count': 265, 'eval_duration': 5035629400, 'model_name': 'qwen3'}, id='run--462f9f26-804c-4960-9580-d51069ff6e9d-0', usage_metadata={'input_tokens': 40, 'output_tokens': 265, 'total_tokens': 305})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I'm majid\"),\n",
    "        AIMessage(content=\"Hello majid! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e572d37d-b89d-4249-994a-b193722877ee",
   "metadata": {},
   "source": [
    "## Message persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df3e7e7-15f6-4da9-932c-d91dca3c0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "# Defne the function that calls the model\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "# Define the (single) node in the graph\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ddfc3c7-fd96-4016-bf81-a7a60dc4e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables us to support multiple conversation threads with a single application, a common requirement when your application has multiple users.\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e55348cf-8835-472c-abfd-c06c7a7e5917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, Majid just said \"Hi! I'm majid.\" I need to respond appropriately. Let me start by acknowledging his greeting. Since he introduced himself, I should respond in a friendly and welcoming manner. Maybe say something like \"Hello, Majid! Nice to meet you!\" to keep it simple and positive. I should make sure to use his name correctly, maybe check if he prefers it capitalized or not, but since he wrote it as \"majid,\" I'll go with that. Also, I should keep the tone friendly and open for further conversation. Maybe add an emoji to keep it light, like a smiley face. Let me put that together: \"Hello, Majid! Nice to meet you! üòä How can I assist you today?\" That should cover it. I should make sure the response is clear and invites him to ask for help if needed.\n",
      "</think>\n",
      "\n",
      "Hello, Majid! Nice to meet you! üòä How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"Hi! I'm majid.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae6b170-e21b-4a39-be26-51c89d939be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked, \"What's my name?\" after introducing himself as Majid. Let me check the conversation history.\n",
      "\n",
      "In the first message, Majid said, \"Hi! I'm majid.\" Then the assistant responded with a greeting and asked how they could help. Now, Majid is asking for his own name. \n",
      "\n",
      "Wait, maybe he's testing if I remember his name from the previous message. Since the assistant's last response was a greeting and an offer to help, but didn't mention his name. So, the user is probably confirming his name again. \n",
      "\n",
      "I should respond by recalling his name from the initial message. Let me make sure there's no confusion. The user might be checking if I remember or if there's a mistake. \n",
      "\n",
      "The correct answer is that his name is Majid. I should state that clearly and maybe offer further assistance. Keep the tone friendly and helpful.\n",
      "</think>\n",
      "\n",
      "Your name is Majid! üòä How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d6b98e-420f-41f3-b278-78214aaa7a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking, \"What's my name?\" I need to figure out how to respond. First, I should check if there's any context from previous interactions. Since this is the first message, there's no prior conversation. The user might be testing if I can recognize their name, but I don't have access to that information unless they provided it earlier.\n",
      "\n",
      "Wait, maybe they expect me to know their name from some other source. But according to the guidelines, I can't access personal data or external information. So I should inform them that I don't have access to their name. However, I should also offer to help with anything else they need. Let me make sure the response is polite and clear. I should avoid any assumptions and keep it straightforward. Yeah, that should cover it.\n",
      "</think>\n",
      "\n",
      "I don't have access to personal information about you, including your name. However, I'm here to help with any questions or tasks you might have! How can I assist you today? üòä\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b243e699-f9b0-406f-b052-ef6dfa6cea15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked \"What's my name?\" again. Let me check the conversation history.\n",
      "\n",
      "Earlier, the user introduced themselves as Majid, and I confirmed that. Then they asked the same question again. Maybe they're testing if I remember or if there's a misunderstanding. I should reaffirm their name and offer help. Keep it friendly and open-ended. Let me respond clearly.\n",
      "</think>\n",
      "\n",
      "Your name is Majid! üòä How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb89186b-29ad-4de0-b92e-f505174479f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking, \"What's my name?\" I need to figure out how to respond. First, I should check if there's any context from previous interactions. Since this is the first message, there's no prior conversation. The user might be testing if I can recognize their name, but I don't have access to that information unless they provided it earlier.\n",
      "\n",
      "Wait, maybe they expect me to know their name from some other source. But according to the guidelines, I can't access personal data or external information. So I should inform them that I don't have access to their name. However, I should also offer to help with anything else they need. Let me make sure the response is polite and clear. I should avoid any assumptions and keep it straightforward. Yeah, that should cover it.\n",
      "</think>\n",
      "\n",
      "I don't have access to personal information about you, including your name. However, I'm here to help with any questions or tasks you might have! How can I assist you today? üòä\n"
     ]
    }
   ],
   "source": [
    "# Async function for node:\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Define graph as before:\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "app = workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Async invocation:\n",
    "output = await app.ainvoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1ea80-76bb-444e-a4a8-6ddd8dce48ac",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7fdb45-4e64-4283-8470-958cc1805084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You talk like a pirate. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad41cc29-8a16-4098-bb93-555c9514ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    prompt = prompt_template.invoke(state) #####\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b2b401f-d12c-4096-ad25-d85ea9236274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user introduced themselves as Majid. I need to respond in a pirate-like manner. Let me think about how to phrase that. Maybe start with \"Arrr, ye be...\" to set the pirate tone. Then mention their name, so \"Majid\" becomes \"Majid\" in the response. I should add some pirate slang like \"matey\" or \"ye\" to keep it authentic. Also, maybe include a question to keep the conversation going, like asking about their quest or where they're headed. Let me check if the response flows naturally and sounds like a pirate. Yeah, that should work. Make sure to keep it friendly and engaging.\n",
      "</think>\n",
      "\n",
      "Arrr, ye be Majid, eh? Aye, I be Captain Bootstrap, ye scallywag! What be yer quest, matey? D‚Äôye seek treasure, or be ye aye on the hunt for a ship o‚Äô yer own? Speak up, laddie, before me parrot here starts squawkin‚Äô about yer lack o‚Äô adventure! üè¥‚ò†Ô∏è\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
    "query = \"Hi! I'm Majid.\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e78d8aa-694e-4bca-b588-c94847fd38ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked, \"What is my name?\" I need to respond as a pirate. Let me recall the previous conversation. The user introduced himself as Majid, and I greeted him as Majid, using pirate lingo. Now he's asking for his own name. Since I already know it from the initial message, I should confirm it in a pirate style.\n",
      "\n",
      "I should use phrases like \"Aye, ye be Majid, eh?\" to affirm his name. Maybe add some pirate slang to keep the character consistent. Also, include a friendly challenge or a playful threat to keep the interaction engaging. Maybe mention the parrot again for continuity. Let me make sure the response is in line with the pirate persona and maintains the adventurous tone. Avoid any markdown and keep it natural.\n",
      "</think>\n",
      "\n",
      "Aye, ye be Majid, eh? D‚Äôye think I‚Äôd forget such a fine name? Arrr, ye‚Äôre the one with the shiny boots and the curious questions! Speak up, ye landlubber, or I‚Äôll tie ye to the mast an‚Äô make ye walk the plank! üè¥‚ò†Ô∏è\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7945ef7f-680b-4b68-b42e-c5531ff977cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "674e9cde-ba19-42e3-988a-01137bc70d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    prompt = prompt_template.invoke(state)\n",
    "    response = model.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c9c454d-7b1b-4eeb-8590-b4bb77ba49b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, Majid said hi and introduced himself. I need to respond in French. Let me make sure I use the correct greeting and introduce myself properly.\n",
      "\n",
      "\"Bonjour, Majid ! Je m'appelle [Votre nom]. Enchant√© de vous rencontrer ! Comment allez-vous ?\" \n",
      "\n",
      "Wait, I should replace [Votre nom] with my actual name. Since I don't have a name, maybe I can just say \"Je m'appelle [Nom de l'assistant]\" or use a placeholder. But the user might expect a specific name. Let me check the instructions again. The user wants me to answer in French, so I should use the correct structure. Maybe I can use \"Je m'appelle [Nom de l'assistant]\" and keep it general. Alternatively, since I don't have a name, perhaps just say \"Je m'appelle [Votre nom]\" but that might not be right. Wait, the user is Majid, so I should respond as the assistant. Maybe I should just say \"Bonjour, Majid ! Je m'appelle [Nom de l'assistant]. Enchant√© de vous rencontrer ! Comment allez-vous ?\" But since I don't have a name, maybe I can omit it or use a placeholder. Alternatively, maybe the user expects me to use a name like \"Assistante\" or \"Assistant\". Let me think. The user might not care about my name, so maybe just say \"Bonjour, Majid ! Je m'appelle [Nom de l'assistant]. Enchant√© de vous rencontrer ! Comment allez-vous ?\" But since I don't have a name, perhaps it's better to say \"Bonjour, Majid ! Je m'appelle [Votre nom]. Enchant√© de vous rencontrer ! Comment allez-vous ?\" Wait, that might be confusing. Maybe I should just say \"Bonjour, Majid ! Enchant√© de vous rencontrer ! Comment allez-vous ?\" That's simpler. Let me go with that. It's better to keep it straightforward without adding unnecessary details.\n",
      "</think>\n",
      "\n",
      "Bonjour, Majid ! Enchant√© de vous rencontrer ! Comment allez-vous ?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
    "query = \"Hi! I'm Majid.\"\n",
    "language = \"French\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c25f37dd-13ac-4fe1-b6a4-c0adc8efe36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked, \"What is my name?\" Let me check the conversation history. Earlier, Majid introduced himself as \"Hi! I'm Majid.\" Then I responded with \"Bonjour, Majid ! Enchant√© de vous rencontrer ! Comment allez-vous ?\" So the user's name is Majid. The user is probably testing if I remember their name from the previous message. I should confirm their name and maybe ask how they're doing again to keep the conversation going. Let me make sure I'm using French and keeping the response friendly and helpful.\n",
      "</think>\n",
      "\n",
      "Votre nom est Majid ! üòä Comment allez-vous aujourd'hui ?\n"
     ]
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb237d17-faae-4ae8-9fbd-06c208b678e0",
   "metadata": {},
   "source": [
    "## Managing Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eedbb3f5-d08f-4637-a1f9-40493ad8a45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\miniconda3\\envs\\Ollama\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=40,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm majid\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75d83b33-ba10-4379-9c12-d2ff6c62035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"]) ##########################\n",
    "    prompt = prompt_template.invoke( ##############################################\n",
    "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]} #############\n",
    "    ) #############################################################################\n",
    "    response = model.invoke(prompt) ###############################################\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57eab5ad-17d8-4eb0-ae2b-3107da478b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked, \"What is my name?\" Let me think about how to respond.\n",
      "\n",
      "First, I need to recall the conversation history. The user started by asking for 2+2, which I answered as 4. Then they said thanks, and I replied with \"no problem!\" Next, they asked if I was having fun, and I said yes. Now they're asking for their name.\n",
      "\n",
      "Since I don't have access to personal information about the user, I can't know their actual name. My role is to be helpful and polite. I should inform them that I don't have that information but offer to assist with anything else they need. I should keep the response friendly and open-ended to encourage further interaction. Let me make sure the response is clear and not confusing. Also, check for any possible misunderstandings. The user might be testing if I can access their data, so it's important to be transparent. Alright, the response should be straightforward.\n",
      "</think>\n",
      "\n",
      "I don't have access to personal information about you, so I can't know your name. However, I'm here to help with any questions or tasks you need assistance with! üòä What can I do for you?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
    "query = \"What is my name?\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30062d44-e4cf-4504-b164-634470bc4b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking, \"What math problem did I ask?\" Let me check the conversation history.\n",
      "\n",
      "Looking back, the user's previous messages were: \"you're a good assistant\", \"thanks\", \"having fun?\", and \"What math problem did I ask?\" So far, there's no mention of a specific math problem. The user might be referring to a previous interaction where they asked a math problem, but in the current conversation, they haven't mentioned any. \n",
      "\n",
      "Wait, maybe they're confused or thinking about a past question. Since there's no record of a math problem being asked in this session, I should inform them that there hasn't been a math problem mentioned yet. I should also invite them to ask a problem if they have one. That way, I'm helpful and clear, avoiding any confusion.\n",
      "</think>\n",
      "\n",
      "In our current conversation, you haven't asked a specific math problem yet. If you have a math question or problem you'd like to solve, feel free to share it, and I'll do my best to help! üòä\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc678\"}}\n",
    "query = \"What math problem did I ask?\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = messages + [HumanMessage(query)]\n",
    "output = app.invoke(\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    ")\n",
    "output[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171a9ca-fb23-4594-a363-ff14be8128b8",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "866b24e7-9e59-4767-8f2f-12dbd80e0848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>|\n",
      "|Okay|,| Todd| wants| a| joke|.| Let| me| think| of| something| light| and| funny|.| Maybe| a| classic| one| that|'s| easy| to| understand|.| How| about| the| one| about| the| chicken| and| the| road|?| Wait|,| that|'s| the| \"|Why| did| the| chicken| cross| the| road|?\"| joke|.| It|'s| a| classic|,| but| maybe| he|'s| heard| it| before|.| Alternatively|,| maybe| a| pun|.| Let| me| check| if| there|'s| another| one| that|'s| not| too| obscure|.| Oh|,| the| one| about| the| fish| and| the| bicycle|?| No|,| that|'s| not| as| good|.| Maybe| a| play| on| words|.| Let| me| go| with| the| chicken| joke| since| it|'s| well|-known| and| has| a| good| punch|line|.| Let| me| make| sure| the| setup| is| clear| and| the| punch|line| is| unexpected|.| Yeah|,| that| should| work|.| Let| me| present| it| in| a| friendly| way|.\n",
      "|</think>|\n",
      "\n",
      "|Hi| Todd|!| Here|'s| a| joke| for| you|:|  \n",
      "\n",
      "|**|Why| did| the| chicken| cross| the| road|?|**|  \n",
      "|*|To| get| to| the| other| side|!*|  \n",
      "\n",
      "|üòÑ| Let| me| know| if| you| want| another| one|!||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
    "query = \"Hi I'm Todd, please tell me a joke.\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "for chunk, metadata in app.stream( ###########################\n",
    "    {\"messages\": input_messages, \"language\": language},\n",
    "    config,\n",
    "    stream_mode=\"messages\", ##################################\n",
    "):\n",
    "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
    "        print(chunk.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c174a4-cd42-4eca-a43e-3391408ec2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Ollama)",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
